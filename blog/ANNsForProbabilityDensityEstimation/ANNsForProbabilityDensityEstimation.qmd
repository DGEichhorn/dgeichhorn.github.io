---
title: "Post titel: PDE via NN"
description: "Post description"
author: "Author"
date: "5/22/2021"
#image: "cover.jpg"
categories:
  - Science
  - Technology
---

ACHTUNG: bei NN training scheint doch noch randomness drin zu sein; WICHTIG SETZE DESHALB WEITERE SEEDS INSBESONDERE FÃœR random

# Load Packages

```{python}
# for sampling
import random
import numpy as np
from scipy import stats

# for visualization
import matplotlib.pyplot as plt

# for constructing, learning, using NNs
import torch
import torch.nn as nn
import torch.optim as optim
```

# Data Generation

```{python}
# construct 2-component Gaussian mixture distribution
comp1 = stats.Normal(mu=2, sigma=0.25)
comp2 = stats.Normal(mu=6, sigma=0.5)
mix = stats.Mixture([comp1, comp2], weights=[0.2, 0.8])
```

# Visualization of the analytic PDF

```{python}
#| code-fold: true
#| code-summary: "Show code"

x = np.linspace(0, 10, 1000)

plt.figure(figsize=(8,5))
plt.plot(x, mix.pdf(x), color="C0", linestyle="dotted")
plt.title("True Probability Density Function")
plt.xlabel("Density")
plt.ylabel("x")
plt.show()
```

# Visualization of Histogram

# Define Neural Network

```{python}
class Network(nn.Module):
  def __init__(self, input_size, hidden_size, output_size):
    super(Network, self).__init__()
    self.net = nn.Sequential(
      nn.Linear(input_size, hidden_size),
      nn.Tanh(),
      nn.Linear(hidden_size, output_size),
      nn.Sigmoid()
      )
    
  def forward(self, x):
    return self.net(x)

```

# Define Custom Loss Function

```{python}
class LossPDE(nn.Module):
  def __init__(self):
    super(LossPDE, self).__init__()
  
  def forward(self, y_pred, y_true, lambda_mon, mon_l, mon_u):
    loss_prediction = torch.mean((y_pred - y_true)**2)
    
    diff = mon_l - mon_u
    loss_monotonicity = torch.mean(torch.clamp(diff, min=0))
    
    loss_total = loss_prediction + lambda_mon*loss_monotonicity
    
    return loss_total

```

# Construct model, loss and optimizer

```{python}
model = Network(input_size=1, hidden_size=10, output_size=1)
criterion = LossPDE()
optimizer = optim.Adam(model.parameters(), lr=1e-3)
```

# Sample data and set monotonicity points

```{python}
# sample data, sort it and convert to torch tensor
n = 200
rng = np.random.default_rng(42)
x = mix.sample(n, rng=rng)
x = torch.from_numpy(np.sort(x)).float().unsqueeze(1)

# set monotonicity points
lambda_mon = 1e6
n_mon_points = 1000
mon_points = torch.linspace(x[0,0], x[-1,0], n_mon_points)[:, None]
delta = 0.1*(max(x)-min(x))/n_mon_points
```

# Training

wichtiger kommentar: in jedem step wird ganzer datensatz verwendet; epochs dienen nur dazu dass nicht in jedem step fortschritt gedruck wird

```{python}
#| output: false

seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)

num_epochs = 200
steps_per_epoch = 1000

for epoch in range(num_epochs):
  for step in range(steps_per_epoch):
    preds = model(x)
    
    u = np.random.uniform(0, 1, n)
    u = torch.from_numpy(np.sort(u)).float().unsqueeze(1)
    
    mon_l = model(mon_points)
    mon_u = model(mon_points + delta)
    
    loss = criterion(preds, u, lambda_mon, mon_l, mon_u)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
  print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}", end="\r", flush=True)

```

```{python}
#| code-fold: true
#| code-summary: "Show code"

xx = torch.linspace(0, 10, 1000).unsqueeze(1)
with torch.no_grad():
    cdf_est = model(xx)

plt.figure(figsize=(8, 5))
plt.plot(xx.numpy(), cdf_est.numpy(), color="C3", label="Estimated CDF")
plt.plot(xx.numpy(), mix.cdf(xx), color="C0", label="True CDF", linestyle="dotted")
plt.title("Cumulative Density Function (CDF)")
plt.xlabel("x")
plt.ylabel("Cumulative Density")
plt.legend()
plt.show()

```

# Function to compute derivate of NN w.r.t. to input x

```{python}
def ComputePDF(model, x):
  x = x.requires_grad_(True)
  cdf = model(x)
  grad_outputs = torch.ones_like(cdf)
  pdf = torch.autograd.grad(
    outputs=cdf,
    inputs=x,
    grad_outputs=grad_outputs
    )[0]
  return pdf

```

# Plot PDF

```{python}
#| code-fold: true
#| code-summary: "Show code"

pdf_est = ComputePDF(model, xx).detach()
xx_np = xx.detach().numpy()


plt.figure(figsize=(8, 5))
plt.plot(xx_np, pdf_est.numpy(), color="C3", label="Estimated PDF")
plt.plot(xx_np, mix.pdf(xx_np), color="C0", label="True PDF", linestyle="dotted")
plt.title("Probability Density Function (PDF)")
plt.xlabel("x")
plt.ylabel("Density")
plt.legend()
plt.show()

```
