---
title: "Learning to Rank"
description: "In this post, I implement from scratch two different approaches for learning a ranking from data on the results of pairwise comparisons."
author: "Alicia"
date: "5/22/2021"
image: "cover.jpg"
categories:
  - Ranking
  - Optimization
  - Maximum Likelihood
---

# Motivation

Probably everyone is familiar with those tables in sports that rank teams, usually according to the number of games won. This seems to be a valide approach for tournaments where every team plays against every other team the same number of times. Such tournaments are called robin-round tournaments and examples include the Premier League as well as the Fußball and the Handball Bundesliga. Robin-round tournaments are a special type of complete comparisons.

However, there are also tournaments in which not every team plays against every other team, i.e. incomplete comparisons. Examples include the NFL in American Football or knock-out tournaments such as playoffs or cups. In such tournaments, some teams might face on average stronger opponents than other teams. Therefore, the number of wins may not reflect the true strength of a team and should not be used to rank teams. Instead, it becomes important, how strong the opponents were, against which a team won or lost.

So I was wondering, what approaches there are for learning a ranking from data on the outcome of incomplete pairwise comparisons. Note that this problem does not just arise in sports but in a variety of other domains. For instance, in preference modelling, multiple individuals must choose between different pairs of items. Based on the outcomes, one tries to rank all of the items. Nevertheless, I will stick to the application in sports.

I found among others two interesting approaches: the PageRank algorithm and the Bradley-Terry model. I will implement both from scratch in R after having shortly described them. Furthermore, I will compare the results of my own implementation to the ones returned by dedicated libraries. For illustration, I will use data on the outcome of every NFL game played during the 2024-2025 regular season.


# Data

Before diving into the two approaches, I scrape and prepare the data on the outcome of every NFL game played during the 2024-2025 regular season. The data is available at: <https://www.pro-football-reference.com/years/2024/games.htm>.

```{r}
#| warning: false

library(rvest)        # web page scraping
library(dplyr)        # data manipulations


url <- "https://www.pro-football-reference.com/years/2024/games.htm#games"
page <- read_html(url)

games <- page %>%
  html_node("table#games") %>%
  html_table(header=TRUE) %>%
  as.data.frame()

# drop irrelevant cols
games <- games[, c(1,5,7)]
names(games) <- c("Week", "Winner", "Loser")

# keep only games during regular season (i.e. int-valued week)
games <- games %>%
  filter(grepl("^[0-9]+$", Week)) %>%
  select(Winner, Loser)

teams <- sort(unique(c(games$Winner, games$Loser)))
n_teams <- length(teams)

head(games)
```

For both approaches, it is more useful to aggregate the outcomes of the games in a win matrix. The win matrix is given by:
$$W=[w_{ij}]_{i=1,\dots,\, n, j=1, \dots, n}$$
where $w_{ij}$ is the number of times team $i$ has won against team $j$. In total there are $n=32$ teams in the NFL. The win matrix is computed as follows:

```{r}
# initialize win matrix with zeros
W <- matrix(
  rep(0, n_teams^2),
  nrow = n_teams,
  dimnames = list(
    teams, # row names
    teams  # col names
  )
)

# fill win matrix
# iterate over all games
for (g in 1:dim(games)[1]) {
  W[games[g, "Winner"], games[g, "Loser"]] <- 
    W[games[g, "Winner"], games[g, "Loser"]] + 1
}
```

# PageRank

## Approach

## Implementation


# Bradley-Terry Model

Under the Bradley-Terry model, the probability that in a direct comparison team $i$ would beat team $j$ is given by:
$$ P(\text{"i beats j"}) = \frac{\theta_i}{\theta_i + \theta_j}$$
for $i,j = 1, \dots, n, i \neq j$. $\theta_i$ can be thought of as measuring the strength of team $i$. Ceteris paribus, the greater $\theta_i$, the greater the probability that team $i$ wins against any other team.

Given theta i for all teams, the teams can be ranked from strongest to weakest by sorting them according to theta in descending order.

zuerst muss man jedoch basierend auf historical comparison data die thetas schätzen mittels maximum likelihood estimation

die wahrscheinlichkeit dass

Under independence the likelihood function (i.e. the probability of the observed data under theta or theta vector) is 
$$ \prod_{i=1}^n \prod_{j=1,\\j \neq i}^n \left(\frac{\theta_i}{\theta_i + \theta_j}\right)^{w_{ij}} $$
can equivalently be written as (alles ohne $j\neq i$) when setting $w_{ii}=0$

AB HIER KÖNNTE ICH MIR DANN SPAREN DAS $j\neq i$ ANDAUERND RUMZUSCHLEIFEN

mle estimate is then arg max likelihood

taking the log: wieso zulässig soll ich das rein tun oder gefahr eigenplagiat?

maximize log likelihood

Log likelihood
$$ \sum_{i=1}^n \sum_{j=1, \\ j \neq i}^n w_{ij} \left[\ln (\theta_i) - \ln (\theta_i + \theta_j)\right] = \sum_{i=1}^n \sum_{j=1, \\ j \neq i}^n w_{ij} \ln (\theta_i) - \sum_{i=1}^n \sum_{j=1, \\ j \neq i}^n w_{ij} \ln (\theta_i + \theta_j)$$
Ableiten nach THETAi und null setzen liefert score equation
$$ \frac{\partial }{\partial \, \theta_i} = \sum_{j=1, \\ j \neq i}^n w_{ij} \left[\frac{1}{\theta_i} - \frac{1}{\theta_i + \theta_j}\right] = \sum_{j=1, \\ j \neq i}^n w_{ij} \frac{1}{\theta_i} - \sum_{j=1, \\ j \neq i}^n w_{ij} \frac{1}{\theta_i + \theta_j} = 0 $$



IMPORTANT: not necessary that they have played against each other in the past; I THINK THIS IS ALSO TRUE FOR PAGERANK

## Approach

## Implementation



# Comparison

# Conclusion




# TO DO

1. 2mal metric für vergleich meine lösung vs. package
2. plots zum vergleich der beiden rankings (u.a. plot(log(bt_mle), r))



I am trying to implement various ranking approaches.



# Define function for mle estimation of Bradley Terry Model

```{r}
bradleyterry_mle <- function(W, n_iter=1000){
  p <- dim(W)[1]
  
  theta.old <- rep(1, p)
  names(theta.old) <- colnames(W)
  
  theta.new <- numeric(p)
  names(theta.new) <- colnames(W)
  
  for (k in 1:n_iter) {
    
    for (i in 1:p) {
      theta.new[i] <- 
        sum(W[i,])/(sum((W[i,] + W[,i])/(theta.old[i]+theta.old)))
    }
    
    # divide by geomtric mean
    theta.new <- theta.new/prod(theta.new)^(1/p)
    
    theta.old <- theta.new
  }
  
  return(theta.new)
}
```

apply mle estimation function to W matrix

```{r}
bt_mle <- bradleyterry_mle(W)
```

# Plot ranking results

```{r}
library(ggplot2)      # for visualization

df <- data.frame(
  team = names(bt_mle),
  score = as.numeric(bt_mle)
)

ggplot(df, aes(reorder(team, score), y=score)) +
  geom_col(fill="steelblue") +
  coord_flip() +
  labs(title="TITEL",
       y="y ACHSE",
       x="x ACHSE") +
  theme_minimal()
```

# compare my results to results of R Package Bradley Terry

```{r}
#| warning: false

# evtl nicht die ganze library laden sondern nur BradleyTerry2:: an den notwendigen Stellen nutzen
library(BradleyTerry2)

b<-countsToBinomial(W)
package_model <- BTm(cbind(win1, win2), player1, player2, data=b)
BTabilities(package_model)

# Converting my values into BTm ability values
log(bt_mle/bt_mle[1])


# Converting BTm values to my values
BTabilities <- BTabilities(package_model)[,1]
exp(BTabilities)*bt_mle[1]
```

# Google Page Rank from scratch

```{r}
#| warning: false

p <- n_teams

d <- 0.85

r <- rep(1/p, p)

# W_ij: number of times team j lost against team i
#W

# c_j: number of times team j lost (=colSums of W)

c <- colSums(W)

A <- (1-d)*rep(1,p) %*% t(rep(1,p))/p + d*W%*%diag(1/c) 

for (i in 1:100) {
  r <- A%*%r
}

print(r)
```
# compare my results to R Package results

wichtig: evtl. igraph:: verwenden anstatt gesamte library zu laden um klarer zu machen wo genau wir eigentlich was aus dieser library verwende

```{r}
library(igraph)

graphObj <- graph_from_adjacency_matrix(t(W), weighted = TRUE, mode = "directed")
(prVec <- page_rank(graphObj)$vector)
```


