<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Dominik G. Eichhorn">
<meta name="dcterms.date" content="2025-10-07">
<meta name="description" content="I implement from scratch an approach for estimating an unknown probability density function of a sample using neural networks. To demonstrate that this method works, I apply it to two examples.">

<title>Neural Networks for Probability Density Estimation – Dominik G. Eichhorn</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../inputs/logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-858d365d9a055f8b8ee912346b04f130.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Dominik G. Eichhorn</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-cv" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">CV</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-cv">    
        <li>
    <a class="dropdown-item" href="../../inputs/CV_DominikEichhorn.pdf">
 <span class="dropdown-text">EN</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../inputs/Lebenslauf_DominikEichhorn.pdf">
 <span class="dropdown-text">DE</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html"> 
<span class="menu-text">Coding</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#general-approach" id="toc-general-approach" class="nav-link" data-scroll-target="#general-approach">General Approach</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a>
  <ul class="collapse">
  <li><a href="#define-neural-network" id="toc-define-neural-network" class="nav-link" data-scroll-target="#define-neural-network">Define Neural Network</a></li>
  <li><a href="#define-modified-loss-function" id="toc-define-modified-loss-function" class="nav-link" data-scroll-target="#define-modified-loss-function">Define Modified Loss Function</a></li>
  <li><a href="#gaussian-mixture" id="toc-gaussian-mixture" class="nav-link" data-scroll-target="#gaussian-mixture">Gaussian Mixture</a>
  <ul class="collapse">
  <li><a href="#set-seed" id="toc-set-seed" class="nav-link" data-scroll-target="#set-seed">Set Seed</a></li>
  <li><a href="#construct-model-loss-and-optimizer" id="toc-construct-model-loss-and-optimizer" class="nav-link" data-scroll-target="#construct-model-loss-and-optimizer">Construct Model, Loss and Optimizer</a></li>
  <li><a href="#sample-from-pdf" id="toc-sample-from-pdf" class="nav-link" data-scroll-target="#sample-from-pdf">Sample from PDF</a></li>
  <li><a href="#set-monotonicity-points" id="toc-set-monotonicity-points" class="nav-link" data-scroll-target="#set-monotonicity-points">Set Monotonicity Points</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  <li><a href="#plot-cdf" id="toc-plot-cdf" class="nav-link" data-scroll-target="#plot-cdf">Plot CDF</a></li>
  <li><a href="#compute-pdf" id="toc-compute-pdf" class="nav-link" data-scroll-target="#compute-pdf">Compute PDF</a></li>
  <li><a href="#plot-pdf" id="toc-plot-pdf" class="nav-link" data-scroll-target="#plot-pdf">Plot PDF</a></li>
  </ul></li>
  <li><a href="#weibull-distribution" id="toc-weibull-distribution" class="nav-link" data-scroll-target="#weibull-distribution">Weibull Distribution</a>
  <ul class="collapse">
  <li><a href="#plot-cdf-1" id="toc-plot-cdf-1" class="nav-link" data-scroll-target="#plot-cdf-1">Plot CDF</a></li>
  <li><a href="#plot-pdf-1" id="toc-plot-pdf-1" class="nav-link" data-scroll-target="#plot-pdf-1">Plot PDF</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Neural Networks for Probability Density Estimation</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Deep Learning</div>
    <div class="quarto-category">Python</div>
    <div class="quarto-category">Probability Density Estimation</div>
  </div>
  </div>

<div>
  <div class="description">
    I implement from scratch an approach for estimating an unknown probability density function of a sample using neural networks. To demonstrate that this method works, I apply it to two examples.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Dominik G. Eichhorn </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 7, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The impressive capabilitis of neural networks in typical regression and classification tasks are widely known. Recently, I came across a paper about a lesser known but statistically very interesting application of neural networks that was written some years ago. The paper shows how neural networks can be used for estimating the probability density function of a random variable <span class="citation" data-cites="magdon1998neural">(<a href="#ref-magdon1998neural" role="doc-biblioref">Magdon-Ismail and Atiya 1998</a>)</span>. Before implementing it from scratch in Python, I will first describe the general approach.</p>
</section>
<section id="general-approach" class="level1">
<h1>General Approach</h1>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable with unknown probability density function (PDF) <span class="math inline">\(f_X\)</span> and unknown cumulative density function (CDF) <span class="math inline">\(F_X\)</span>. Given a set of <span class="math inline">\(n \in \mathbb{N}\)</span> i.i.d. realizations of <span class="math inline">\(X\)</span>, <span class="math inline">\(x_i, i=1, \dots, n\)</span>, the goal is to estimate <span class="math inline">\(f_X\)</span>. In contrast to other approaches, such as Kernel Density Estimators, the approach by <span class="citation" data-cites="magdon1998neural">Magdon-Ismail and Atiya (<a href="#ref-magdon1998neural" role="doc-biblioref">1998</a>)</span> does not directly estimate the PDF.</p>
<p>Instead, the approach by <span class="citation" data-cites="magdon1998neural">Magdon-Ismail and Atiya (<a href="#ref-magdon1998neural" role="doc-biblioref">1998</a>)</span> relies on the following two useful properties of the <strong>CDF</strong>:</p>
<ol type="1">
<li>If the CDF is differentiable, the PDF is obtained as the derivative of the CDF, i.e., <span class="math inline">\(f_X(x)=\frac{d \, F_X}{d \, x}(x)\)</span>.</li>
<li>Transforming a random variable by its own CDF yields a new random variable that is uniformly distributed on <span class="math inline">\((0,1)\)</span>, i.e., <span class="math inline">\(F_X(X) \sim \mathcal{U}(0,1)\)</span>.</li>
</ol>
<p><span class="citation" data-cites="magdon1998neural">Magdon-Ismail and Atiya (<a href="#ref-magdon1998neural" role="doc-biblioref">1998</a>)</span> proposed to use a neural network, which needs to be differentiable, to approximate the <strong>CDF</strong> and take afterwards the first derivative w.r.t. <span class="math inline">\(x\)</span> to obtain an estimate of the <strong>PDF</strong>. Let <span class="math inline">\(N_{\theta}(x)\)</span> denote a feed forward multilayer perceptron parametrized by <span class="math inline">\(\theta\)</span> (i.e.&nbsp;a vector containing all weights and biases), <span class="math inline">\(N_{\theta}: \mathbb{R} \to \mathbb{R}\)</span>. <span class="math inline">\(N_{\theta}\)</span> is differentiable, if the activation functions employed by it are differentiable (since it is then a composition of differentiable functions). <span class="math inline">\(tanh\)</span> and <span class="math inline">\(sigmoid\)</span> are examples of differentiable activation functions.</p>
<p>So the goal is to find the parameter vector <span class="math inline">\(\theta^\star\)</span> for which <span class="math inline">\(N_{\theta^\star}(x) = F_X(x)\)</span> for all <span class="math inline">\(x \in \mathbb{R}\)</span>. However, that is the same as finding the parameter vector <span class="math inline">\(\theta^\star\)</span> for which the transformed random variable <span class="math inline">\(N_{\theta^\star}(X)\)</span> is uniformly distributed on <span class="math inline">\((0,1)\)</span>, since <span class="math inline">\(F_X(X) \sim \mathcal{U}(0,1)\)</span>. This is achieved by the following procedure <span class="citation" data-cites="magdon1998neural">(<a href="#ref-magdon1998neural" role="doc-biblioref">Magdon-Ismail and Atiya 1998</a>)</span>: Beforehand, the realizations of the random variable <span class="math inline">\(X\)</span> are sorted in ascending order, i.e.&nbsp;<span class="math inline">\(x_{[1]} \leq \dots \leq x_{[n]}\)</span>. These <span class="math inline">\(x_{[i]}, i=1,\dots, n\)</span>, serve as inputs. During training, in each iteration step <!--$t \in \mathbb{N}$-->, first, a new set of <span class="math inline">\(n\)</span> samples are drawn i.i.d. from a uniform distribution on <span class="math inline">\((0,1)\)</span>, <span class="math inline">\(u_i \sim \mathcal{U}(0,1)\)</span>, and sorted in ascending order, i.e.&nbsp;<span class="math inline">\(u_{[1]} \leq \dots \leq u_{[n]}\)</span>. These <span class="math inline">\(u_{[i]}, i=1,\dots, n\)</span>, serve as targets only for that iteration step. Second, a gradient descent step is taken to adjust the parameter vector to better map the inputs onto the generated targets. For the purpose of mapping the data to a uniform distribution, the following loss function is a reasonable starting point: <span class="math display">\[ L_{dist}(\theta) = \frac{1}{n} \sum_{i=1}^n \left[ N_{\theta}(x_{[i]}) -  u_{[i]}\right]^2 \]</span></p>
<p>However, besides from mapping the data to a uniform distribution, there are two further properties, that CDFs exhibit and that the neural network approximation to the CDF must also have to be a legitimate estimate of a CDF. <!--Note that a CDF cannot be any arbitrary function. In fact, a CDF must have two further important properties that the neural network approximation to the CDF should also exhibit: --> First, the CDF maps <span class="math inline">\(\mathbb{R}\)</span> onto the interval <span class="math inline">\([0,1]\)</span>. Second, the CDF is monotonically increasing. By using an activation function in the output layer that maps <span class="math inline">\(\mathbb{R}\)</span> onto the interval <span class="math inline">\([0,1]\)</span>, it can be guaranteed that the neural network approximation to the CDF satisfies the first property. The second property can be enforced by modifying the loss function. The modified loss function <span class="math inline">\(L_{total}\)</span> also includes a term, <span class="math inline">\(L_{mon}\)</span>, that applies a penalty if the neural network approximation to the CDF is not monotonically increasing in <span class="math inline">\(x\)</span>. More specifically, <span class="math inline">\(L_{mon}\)</span> is written as: <span class="math display">\[ L_{mon}(\theta) = \frac{1}{n_{mon}} \sum_{k=1}^{n_{mon}} \max \left( N_{\theta}(x_k^{mon}) - N_{\theta}(x_k^{mon} + \Delta), 0 \right)\]</span> for some small <span class="math inline">\(\Delta &gt; 0\)</span> with <span class="math inline">\(x_k^{mon}, k=1,\dots, n_{mon},\)</span> being a set of <span class="math inline">\(n_{mon} \in \mathbb{N}\)</span> points at which monotonicity is to be enforced.</p>
<p>The resulting modified loss function is: <span class="math display">\[ L_{total}(\theta) = L_{dist}(\theta) + \lambda_{mon} \, L_{mon}(\theta) \]</span> where <span class="math inline">\(\lambda_{mon} \in \mathbb{R}_{&gt;0}\)</span> is a large positive weighting factor for the monotonicity constraint. <span class="math inline">\(\theta^\star\)</span> is then given by: <span class="math display">\[\theta^\star = \underset{\theta}{\text{arg min}} \; L_{total}(\theta)\]</span> Once <span class="math inline">\(\theta^\star\)</span> is computed using standard gradient based methods, the estimated PDF <span class="math inline">\(\hat{f}_X\)</span> is obtained by <span class="math display">\[ \hat{f}_X(x) = \frac{\partial \, N_{\theta^\star}(x)}{\partial \, x}  \]</span></p>
<p>exploiting the differentiability of <span class="math inline">\(N_{\theta}\)</span> using backpropagation.</p>
<p>In summary, the procedure for estimating the <strong>PDF</strong> using neural network is given by:</p>
<ol type="1">
<li><p>Sort the realizations of the random variable <span class="math inline">\(X\)</span> in ascending order, i.e., <span class="math inline">\(x_{[1]} \leq \dots \leq x_{[n]}\)</span>.</p></li>
<li><p>Initialize the parameter vector <span class="math inline">\(\theta\)</span> randomly.</p></li>
<li><p>Repeat until convergence:</p>
<ol type="1">
<li><p>Draw <span class="math inline">\(n\)</span> i.i.d. realizations from a uniform distribution on <span class="math inline">\((0,1)\)</span>, <span class="math inline">\(u_i \sim \mathcal{U}(0,1)\)</span>, and sort them in ascending order, i.e., <span class="math inline">\(u_{[1]} \leq \dots \leq u_{[n]}\)</span>.</p></li>
<li><p>Update the parameter vector: <span class="math display">\[ \theta \gets \theta - \eta \times \frac{\partial \, L_{total}(\theta)}{\partial \, \theta} \]</span></p></li>
</ol></li>
<li><p>Determine the estimated PDF as <span class="math display">\[ \hat{f}_X(x) = \frac{\partial \, N_{\theta^\star}(x)}{\partial \, x}  \]</span> using backpropagation.</p></li>
</ol>
</section>
<section id="implementation" class="level1">
<h1>Implementation</h1>
<p>After detailing the general approach for solving ODEs using neural networks, in this section, I will implement it from scratch in Python and apply it to two different examples.</p>
<div id="6227407a" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># for sampling</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># for visualization</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># for constructing, learning, using NNs</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="define-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="define-neural-network">Define Neural Network</h2>
<p>At first, I define the neural network used for approximating the CDF. It is a fully connected feed forward neural network with one hidden layer using a <span class="math inline">\(tanh\)</span> activation function and an output layer using a <span class="math inline">\(sigmoid\)</span> activation function. Thereby, the neural network is differentiable and maps <span class="math inline">\(\mathbb{R}\)</span> onto the interval <span class="math inline">\((0,1)\)</span>.</p>
<div id="bf52f587" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> N(nn.Module):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size, output_size):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>(N, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>      nn.Linear(input_size, hidden_size),</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>      nn.Tanh(),</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>      nn.Linear(hidden_size, output_size),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>      nn.Sigmoid()</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.net(x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="define-modified-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="define-modified-loss-function">Define Modified Loss Function</h2>
<p>Next, I define the modified loss function as described above.</p>
<div id="dec530f0" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Loss(nn.Module):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>(Loss, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, y_pred, y_true, lambda_mon, mon_l, mon_u):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    loss_dist <span class="op">=</span> torch.mean((y_pred <span class="op">-</span> y_true)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    diff <span class="op">=</span> mon_l <span class="op">-</span> mon_u</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    loss_mon <span class="op">=</span> torch.mean(torch.clamp(diff, <span class="bu">min</span><span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    loss_total <span class="op">=</span> loss_dist <span class="op">+</span> lambda_mon<span class="op">*</span>loss_mon</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss_total</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="gaussian-mixture" class="level2">
<h2 class="anchored" data-anchor-id="gaussian-mixture">Gaussian Mixture</h2>
<p>For the first example, realizations will be drawn from a 2-component Gaussian mixture distribution. So I construct one with mixture weights <span class="math inline">\(\phi_1=0.2\)</span> and <span class="math inline">\(\phi_2=0.8\)</span>, expectations <span class="math inline">\(\mu_1=2\)</span> and <span class="math inline">\(\mu_2=5\)</span> and standard deviations <span class="math inline">\(\sigma_1=0.25\)</span> and <span class="math inline">\(\sigma_2=0.5\)</span>.</p>
<div id="28bb193f" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># construct 2-component Gaussian mixture distribution</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>comp1 <span class="op">=</span> stats.Normal(mu<span class="op">=</span><span class="dv">2</span>, sigma<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>comp2 <span class="op">=</span> stats.Normal(mu<span class="op">=</span><span class="dv">5</span>, sigma<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>mix <span class="op">=</span> stats.Mixture([comp1, comp2], weights<span class="op">=</span>[<span class="fl">0.2</span>, <span class="fl">0.8</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The corresponding PDF looks as follows:</p>
<div id="00238a69" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">1000</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">5</span>))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.plot(x, mix.pdf(x), color<span class="op">=</span><span class="st">"C0"</span>, linestyle<span class="op">=</span><span class="st">"dotted"</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"True Probability Density Function"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANNsForProbabilityDensityEstimation_files/figure-html/cell-6-output-1.png" width="514" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="set-seed" class="level3">
<h3 class="anchored" data-anchor-id="set-seed">Set Seed</h3>
<p>In the subsequent steps, the neural network will be initialized and realizations will be sampled from the PDF given above. Both involves randomness. Therefore, to ensure reproducibility of the subsequent steps, one must set a seed for the random number generators.</p>
<div id="75236b32" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>random.seed(seed)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(seed)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>&lt;torch._C.Generator at 0x1e0c59be7b0&gt;</code></pre>
</div>
</div>
</section>
<section id="construct-model-loss-and-optimizer" class="level3">
<h3 class="anchored" data-anchor-id="construct-model-loss-and-optimizer">Construct Model, Loss and Optimizer</h3>
<p>After that, I instantiate the neural network, the loss function to be minimized and the optimizer (here, I use Adam).</p>
<div id="d4f3ef7d" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> N(input_size<span class="op">=</span><span class="dv">1</span>, hidden_size<span class="op">=</span><span class="dv">10</span>, output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> Loss()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="sample-from-pdf" class="level3">
<h3 class="anchored" data-anchor-id="sample-from-pdf">Sample from PDF</h3>
<p>Next, I sample <span class="math inline">\(n=200\)</span> i.i.d. realizations from the 2-component Gaussian mixture distribution. Subsequently, I sort then in ascending order.</p>
<div id="48795315" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample data, sort it and convert to torch tensor</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(seed)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> mix.sample(n, rng<span class="op">=</span>rng)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.from_numpy(np.sort(x)).<span class="bu">float</span>().unsqueeze(<span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="set-monotonicity-points" class="level3">
<h3 class="anchored" data-anchor-id="set-monotonicity-points">Set Monotonicity Points</h3>
<p>Before training can start, I have to specify <span class="math inline">\(\lambda_{mon}\)</span>, <span class="math inline">\(n_{mon}\)</span>, the monotonicity points themselves as well as <span class="math inline">\(\Delta\)</span>. I choose to place <span class="math inline">\(n_{mon}=1000\)</span> monotonicity points equally spaced between the smallest and the largest sampled <span class="math inline">\(X\)</span>-values.</p>
<div id="d9e716b6" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set monotonicity points</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>lambda_mon <span class="op">=</span> <span class="fl">1e6</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>n_mon <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>mon_points <span class="op">=</span> torch.linspace(x[<span class="dv">0</span>,<span class="dv">0</span>], x[<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>], n_mon)[:, <span class="va">None</span>]</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>delta <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>(<span class="bu">max</span>(x)<span class="op">-</span><span class="bu">min</span>(x))<span class="op">/</span>n_mon</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="training" class="level3">
<h3 class="anchored" data-anchor-id="training">Training</h3>
<p>Now, everything is set up and training can start. Observe that, as described in the general approach, in each iteration, a new set of <span class="math inline">\(n\)</span> samples are drawn i.i.d. from <span class="math inline">\(\mathcal{U}(0,1)\)</span> and sorted in ascending order. These serve as targets only for that iteration.</p>
<div id="d24a4ae6" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>steps_per_epoch <span class="op">=</span> <span class="dv">2500</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(steps_per_epoch):</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> model(x)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> torch.from_numpy(np.sort(u)).<span class="bu">float</span>().unsqueeze(<span class="dv">1</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    mon_l <span class="op">=</span> model(mon_points)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    mon_u <span class="op">=</span> model(mon_points <span class="op">+</span> delta)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(preds, u, lambda_mon, mon_l, mon_u)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f"Epoch [</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">], Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>, end<span class="op">=</span><span class="st">"</span><span class="ch">\r</span><span class="st">"</span>, flush<span class="op">=</span><span class="va">True</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="plot-cdf" class="level3">
<h3 class="anchored" data-anchor-id="plot-cdf">Plot CDF</h3>
<p>Once training has finished, I plot the learned neural network approximation of CDF against the actual CDF of the 2-component Gaussian mixture.</p>
<div id="13179a1e" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> torch.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">1000</span>).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    cdf_est <span class="op">=</span> model(xx)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.plot(xx.numpy(), cdf_est.numpy(), color<span class="op">=</span><span class="st">"C3"</span>, label<span class="op">=</span><span class="st">"Estimated CDF"</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.plot(xx.numpy(), mix.cdf(xx), color<span class="op">=</span><span class="st">"C0"</span>, label<span class="op">=</span><span class="st">"True CDF"</span>, linestyle<span class="op">=</span><span class="st">"dotted"</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Cumulative Density Function (CDF)"</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Cumulative Density"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANNsForProbabilityDensityEstimation_files/figure-html/cell-12-output-1.png" width="514" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Obviously, the neural network approximation of the CDF given just a sample of 200 realizations of <span class="math inline">\(X\)</span> is very accurate.</p>
</section>
<section id="compute-pdf" class="level3">
<h3 class="anchored" data-anchor-id="compute-pdf">Compute PDF</h3>
<p>Given the neural network approximation of the CDF, the following function computes an estimate of the PDF from it.</p>
<div id="5982741c" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ComputePDF(model, x):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  x <span class="op">=</span> x.requires_grad_(<span class="va">True</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  cdf <span class="op">=</span> model(x)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  grad_outputs <span class="op">=</span> torch.ones_like(cdf)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  pdf <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    outputs<span class="op">=</span>cdf,</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>x,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    grad_outputs<span class="op">=</span>grad_outputs</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    )[<span class="dv">0</span>]</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> pdf</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="plot-pdf" class="level3">
<h3 class="anchored" data-anchor-id="plot-pdf">Plot PDF</h3>
<p>This plot confirms, that the estimate of the PDF obtained from the neural network approximation to the CDF is quite precise.</p>
<div id="f527ccee" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Show code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>pdf_est <span class="op">=</span> ComputePDF(model, xx).detach()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>xx_np <span class="op">=</span> xx.detach().numpy()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>plt.plot(xx_np, pdf_est.numpy(), color<span class="op">=</span><span class="st">"C3"</span>, label<span class="op">=</span><span class="st">"Estimated PDF"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>plt.plot(xx_np, mix.pdf(xx_np), color<span class="op">=</span><span class="st">"C0"</span>, label<span class="op">=</span><span class="st">"True PDF"</span>, linestyle<span class="op">=</span><span class="st">"dotted"</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Probability Density Function (PDF)"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANNsForProbabilityDensityEstimation_files/figure-html/cell-14-output-1.png" width="514" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="weibull-distribution" class="level2">
<h2 class="anchored" data-anchor-id="weibull-distribution">Weibull Distribution</h2>
<p>As second example, I will use a Weibull distribution with <span class="math inline">\(shape=1.8\)</span> (and <span class="math inline">\(scale=1\)</span>).</p>
<div id="fe78e3f1" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># construct Weibull distribution</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>dist <span class="op">=</span> stats.weibull_min(c<span class="op">=</span><span class="fl">1.8</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>A plot of its PDF shows that it is clearly skewed.</p>
<div id="332c64c6" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Show code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">1000</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">5</span>))</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.plot(x, dist.pdf(x), color<span class="op">=</span><span class="st">"C0"</span>, linestyle<span class="op">=</span><span class="st">"dotted"</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"True Probability Density Function"</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANNsForProbabilityDensityEstimation_files/figure-html/cell-16-output-1.png" width="514" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The following steps (set seed; construct model, loss and optimizer; sample from PDF; set monontonicity points; training) are analogous to those in the first example. Therefore, I hide that part of the code. If you wish to have a look at it, click on the “Show code” button below.</p>
<div id="50a4013b" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Show code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set seed</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>random.seed(seed)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(seed)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># construct model, loss and optimizer</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> N(input_size<span class="op">=</span><span class="dv">1</span>, hidden_size<span class="op">=</span><span class="dv">10</span>, output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> Loss()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># sample data, sort it and convert to torch tensor</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(seed)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> dist.rvs(n, random_state<span class="op">=</span>rng)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.from_numpy(np.sort(x)).<span class="bu">float</span>().unsqueeze(<span class="dv">1</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co"># set monotonicity points</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>lambda_mon <span class="op">=</span> <span class="fl">1e6</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>n_mon <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>mon_points <span class="op">=</span> torch.linspace(x[<span class="dv">0</span>,<span class="dv">0</span>], x[<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>], n_mon)[:, <span class="va">None</span>]</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>delta <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>(<span class="bu">max</span>(x)<span class="op">-</span><span class="bu">min</span>(x))<span class="op">/</span>n_mon</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>steps_per_epoch <span class="op">=</span> <span class="dv">2500</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co"># training</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(steps_per_epoch):</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> model(x)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> torch.from_numpy(np.sort(u)).<span class="bu">float</span>().unsqueeze(<span class="dv">1</span>)</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>    mon_l <span class="op">=</span> model(mon_points)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>    mon_u <span class="op">=</span> model(mon_points <span class="op">+</span> delta)</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(preds, u, lambda_mon, mon_l, mon_u)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f"Epoch [</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">], Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>, end<span class="op">=</span><span class="st">"</span><span class="ch">\r</span><span class="st">"</span>, flush<span class="op">=</span><span class="va">True</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="plot-cdf-1" class="level3">
<h3 class="anchored" data-anchor-id="plot-cdf-1">Plot CDF</h3>
<p>Inspecting the below plot of the learned neural network approximation of the CDF and the actual CDF shows again that the neural network was successful in recovering the actual CDF.</p>
<div id="fc96f071" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Show code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> torch.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">1000</span>).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    cdf_est <span class="op">=</span> model(xx)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>plt.plot(xx.numpy(), cdf_est.numpy(), color<span class="op">=</span><span class="st">"C3"</span>, label<span class="op">=</span><span class="st">"Estimated CDF"</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>plt.plot(xx.numpy(), dist.cdf(xx), color<span class="op">=</span><span class="st">"C0"</span>, label<span class="op">=</span><span class="st">"True CDF"</span>, linestyle<span class="op">=</span><span class="st">"dotted"</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Cumulative Density Function (CDF)"</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Cumulative Density"</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANNsForProbabilityDensityEstimation_files/figure-html/cell-18-output-1.png" width="514" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="plot-pdf-1" class="level3">
<h3 class="anchored" data-anchor-id="plot-pdf-1">Plot PDF</h3>
<p>Also when comparing the resulting estimated PDF to the actual one, it seems that neural network approach yields good results.</p>
<div id="21e04e9e" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Show code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>pdf_est <span class="op">=</span> ComputePDF(model, xx).detach()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>xx_np <span class="op">=</span> xx.detach().numpy()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plt.plot(xx_np, pdf_est.numpy(), color<span class="op">=</span><span class="st">"C3"</span>, label<span class="op">=</span><span class="st">"Estimated PDF"</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>plt.plot(xx_np, dist.pdf(xx_np), color<span class="op">=</span><span class="st">"C0"</span>, label<span class="op">=</span><span class="st">"True PDF"</span>, linestyle<span class="op">=</span><span class="st">"dotted"</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Probability Density Function (PDF)"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANNsForProbabilityDensityEstimation_files/figure-html/cell-19-output-1.png" width="514" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-magdon1998neural" class="csl-entry" role="listitem">
Magdon-Ismail, Malik, and Amir Atiya. 1998. <span>“Neural Networks for Density Estimation.”</span> <em>Advances in Neural Information Processing Systems</em> 11.
</div>
<div id="ref-papa2021pytorch" class="csl-entry" role="listitem">
Papa, Joe. 2021. <em>PyTorch Pocket Reference</em>. " O’Reilly Media, Inc.".
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>