[
  {
    "objectID": "blog/LearningToRank/LearningToRank.html#approach",
    "href": "blog/LearningToRank/LearningToRank.html#approach",
    "title": "Learning to Rank",
    "section": "Approach",
    "text": "Approach\nUnder the Bradley-Terry model, the probability that in a direct comparison team \\(i\\) would beat team \\(j\\) is given by: \\[ P(\\text{\"i beats j\"}) = \\frac{\\theta_i}{\\theta_i + \\theta_j}\\] for \\(i,j = 1, \\dots, n, i \\neq j\\). \\(\\theta_i\\) can be thought of as measuring the strength of team \\(i\\). Ceteris paribus, the greater \\(\\theta_i\\), the greater the probability that team \\(i\\) wins against any other team.\nUnder independence, the likelihood function (i.e. the probability of the observed data under \\(\\theta_1, \\dots, \\theta_n\\)) is \\[L(\\theta_1, \\dots, \\theta_n) =  \\prod_{i=1}^n \\prod_{j=1}^n \\left(\\frac{\\theta_i}{\\theta_i + \\theta_j}\\right)^{w_{ij}}.\n\\] Note that \\(w_{ii}\\) is set to 0 as mentioned above. The log-likelihood function is \\[ l(\\theta_1, \\dots, \\theta_n) = \\sum_{i=1}^n \\sum_{j=1}^n w_{ij} \\ln(\\theta_i) - \\sum_{i=1}^n \\sum_{j=1}^n w_{ij} \\ln(\\theta_i + \\theta_j)\\] The maximum likelihood estimates (MLEs) are obtained by maximizing \\(l\\) w.r.t. \\(\\theta_1, \\dots, \\theta_n\\). For this purpose the gradient of \\(l\\) is required. It is given by: \\[ \\begin{align} \\frac{\\partial l}{\\partial \\theta_k}(\\theta_1, \\dots, \\theta_n) &= \\frac{1}{\\theta_k} \\sum_{j=1}^n w_{kj} - \\left[ \\overbrace{ \\sum_{i=1}^n \\frac{w_{ik}}{\\theta_i + \\theta_k}}^{\\text{case: }j=k} + \\overbrace{\\sum_{j=1}^n \\frac{w_{kj}}{\\theta_k + \\theta_j}}^{\\text{case: }i=k} \\right], \\\\\n&= \\frac{1}{\\theta_k} \\sum_{j=1}^n w_{kj} - \\left[ \\sum_{j=1}^n \\frac{w_{jk}}{\\theta_j + \\theta_k} + \\sum_{j=1}^n \\frac{w_{kj}}{\\theta_k + \\theta_j} \\right],\\\\\n&= \\frac{1}{\\theta_k} \\sum_{j=1}^n w_{kj} - \\sum_{j=1}^n \\frac{w_{jk} +w_{kj}}{\\theta_j + \\theta_k} ,  &\\forall k=1,\\dots n \\end{align}\\] Note that I index the differentiation variable by \\(k\\) in order to clearly separate it from the summation index \\(i\\). Setting the gradient equal to 0 and rearranging yields: \\[ \\theta_k = \\frac{\\sum_{j=1}^n w_{kj}}{\\sum_{j=1}^n \\frac{w_{kj} + w_{jk}}{\\theta_k + \\theta_j}}, \\; \\forall k=1,\\dots,n \\] Starting with some initial values \\(\\theta_1^{(0)}, \\dots, \\theta_k^{(0)}\\), and using the above equation, the MLEs are iteratively obtained as follows: \\[\\begin{align}\n\\theta_k^{(t+1)} &\\gets \\frac{\\sum_{j=1}^n w_{kj}}{\\sum_{j=1}^n \\frac{w_{kj} + w_{jk}}{\\theta_k^{(t)} + \\theta_j^{(t)}}}, &\\; \\forall k=1,\\dots,n \\\\\n\\theta_k^{(t+1)} &\\gets \\frac{1}{\\left(\\prod_{j=1}^n \\theta_j^{(t+1)} \\right)^{1/n}}, &\\; \\forall k=1,\\dots,n\n\\end{align}\\] The second operation normalizes the MLEs such that their geometric mean is 1 (Newman 2023)."
  },
  {
    "objectID": "blog/LearningToRank/LearningToRank.html#implementation",
    "href": "blog/LearningToRank/LearningToRank.html#implementation",
    "title": "Learning to Rank",
    "section": "Implementation",
    "text": "Implementation\nHaving outlined how the MLEs are obtained in the Bradley-Terry model, below, you find my from-scratch implementation of it.\n\nmy_bradleyterry &lt;- function(W, n_iter=1000){\n  n &lt;- dim(W)[1]\n  \n  # initialize strength vector theta,\n  # before and after update,\n  # with all teams equally strong\n  theta.old &lt;- rep(1, n)\n  names(theta.old) &lt;- colnames(W)\n  theta.new &lt;- rep(1,n)\n  names(theta.new) &lt;- colnames(W)\n  \n  for (t in 1:n_iter) {\n    for (i in 1:n) {\n      theta.new[i]&lt;-sum(W[i,])/(sum((W[i,]+W[,i])/(theta.old[i]+theta.old )))\n    }\n    \n    # normalize by geomtric mean\n    theta.new &lt;- theta.new/prod(theta.new)^(1/n)\n    \n    # update\n    theta.old &lt;- theta.new\n  }\n  \n  return(theta.new)\n}\n\nI apply my function for computing the MLEs to the winning matrix of the 2024-2025 regular season retrieved above.\n\nmy_btm_mles &lt;- my_bradleyterry(W)\nhead(my_btm_mles)\n\nArizona Cardinals   Atlanta Falcons  Baltimore Ravens     Buffalo Bills \n        1.0972960         0.9883723         3.4372074         3.5989702 \nCarolina Panthers     Chicago Bears \n        0.3647306         0.4153262 \n\n\nNext, I sort the teams in descending order according to their estimated strengths and construct a horizontal bar char.\n\n\nShow code\nlibrary(ggplot2)      # for visualization\n\ndf &lt;- data.frame(\n  team = names(my_btm_mles),\n  score = as.numeric(my_btm_mles)\n)\n\np &lt;- ggplot(df, aes(reorder(team, score), y=score)) +\n  geom_col(fill=\"#0b0b64\") +\n  coord_flip() +\n  labs(title=\"Ranking and Strength based on Bradley-Terry\",\n       y=\"Strength\",\n       x=\"Team\") +\n  theme_light()\n\nggsave(\"cover.jpg\", plot = p, width = 8, height = 6, dpi = 300, bg = \"white\")\n\np\n\n\n\n\n\n\n\n\n\nNow, let’s compare the results of my from-scratch implementation to those of the BradleyTerry2 R package.\n\n# use built-in function to convert W in format required by BradleyTerry2\ndt &lt;- BradleyTerry2::countsToBinomial(W)\n\n# fit Bradley-Terry model using BradleyTerry2\npackage_btm &lt;- BradleyTerry2::BTm(cbind(win1, win2), player1, player2, data=dt)\n\n# extract Bradley-Terry model MLEs\npackage_btm_mles &lt;- BradleyTerry2::BTabilities(package_btm)\n\n\n# compare results\nbtm_compare &lt;- cbind(my_btm_mles, \"package_btm_mles\"=package_btm_mles[,\"ability\"])\nhead(btm_compare)\n\n                  my_btm_mles package_btm_mles\nArizona Cardinals   1.0972960        0.0000000\nAtlanta Falcons     0.9883723       -0.1045449\nBaltimore Ravens    3.4372074        1.1418104\nBuffalo Bills       3.5989702        1.1877988\nCarolina Panthers   0.3647306       -1.1014454\nChicago Bears       0.4153262       -0.9715400\n\n\nAt first sight, it seems that the results returned by the BradleyTerry2 package and my results differ quite alot. Therefore, I had a closer look at the documentation of the BradleyTerry2 package. I found out that they utilize a slightly different specification of the Bradley-Terry model (let’s call it the exponential specification). However, both specifications are equivalent in the sense that, first, both result in the same winning probabilities and, second, that there is an explicit formula for converting their parameters.\nThe exponential specification is given by: \\[P(\\text{\"i beats j\"}) = \\frac{e^{s_i}}{e^{s_i} + e^{s_j}}, \\; \\forall i,j=1,\\dots, n\\] and \\(s_0\\) is set to be 0. The formulas for converting the parameters of the two specifications are: \\[ \\begin{align} s_i = \\ln \\left(\\frac{\\theta_i}{\\theta_0}\\right), \\\\\n\\theta_i = \\exp(s_i) \\times \\theta_0\n\\end{align}\\] So, let’s now convert the parameters I estimated into the format of the exponential specification and then compare it to the output of the BradleyTerry2 package.\n\n\n# compare results\nmy_conv_btm_mles &lt;- log(my_btm_mles/my_btm_mles[1])\nbtm_compare &lt;- cbind(my_btm_mles, my_conv_btm_mles, \"package_btm_mles\"=package_btm_mles[,\"ability\"])\n\n\n# compute Euclidean distance between my_conv_btm_mles and package_btm_mles\ndist &lt;- sqrt(sum((btm_compare[,2]-btm_compare[,3])^2))\nprint(paste(\"Euclidean distance between my_conv_btm_mles and package_btm_mles:\", dist))\n\n[1] \"Euclidean distance between my_conv_btm_mles and package_btm_mles: 5.39456400516441e-12\"\n\nhead(btm_compare)\n\n                  my_btm_mles my_conv_btm_mles package_btm_mles\nArizona Cardinals   1.0972960        0.0000000        0.0000000\nAtlanta Falcons     0.9883723       -0.1045449       -0.1045449\nBaltimore Ravens    3.4372074        1.1418104        1.1418104\nBuffalo Bills       3.5989702        1.1877988        1.1877988\nCarolina Panthers   0.3647306       -1.1014454       -1.1014454\nChicago Bears       0.4153262       -0.9715400       -0.9715400\n\n\nAfter converting my MLEs, they are exactly the same as the MLEs returned by the BradleyTerry2 package."
  },
  {
    "objectID": "blog/LearningToRank/LearningToRank.html#approach-1",
    "href": "blog/LearningToRank/LearningToRank.html#approach-1",
    "title": "Learning to Rank",
    "section": "Approach",
    "text": "Approach\nPageRank does not treat all of the opponents of a given team equally. In fact, it accounts for both, the strength of the opponents as well as their total number of games lost. Opponents with higher strength get more weight, while opponents with a higher total number of games lost get a less weight.\nBased on this mechanism, the strength of team \\(i\\) according to PageRank, \\(p_i\\), is recursively defined as: \\[ p_i = (1-d) + d \\sum_{j=1}^n \\left( \\frac{w_{ij}}{c_j} \\right) p_j \\] As before, \\(w_{ij}\\) is the number of times team \\(i\\) won against team \\(j\\). \\(c_j = \\sum_{i=1}^n w_{ij}\\) is the total numer of games lost by team \\(j\\). The term inside the sum works according to the above described mechanism: Wins against an opponent \\(j\\) with high strength (i.e. high \\(p_j\\)) get more weight, while wins against an opponent with a high number of total games lost (i.e. high \\(c_j\\)) get less weight. This is then summed up across all opponents and weighted by the damping factor \\(d \\in [0,1)\\) (usually, \\(d\\) is set to 0.85). \\(d\\) guarantees the existence of (finite) soultions even if there is a team that always won or always lost.\nThe above can be written in matrix-vector notation as follows: \\[ \\textbf{p} = (1-d) \\, \\textbf{e} + d \\, \\textbf{W} \\,\\textbf{D}_c^{-1} \\, \\textbf{p} \\] where \\(\\textbf{p}=[p_1, \\dots, p_n]^T\\) is the PageRank strength vector and \\(\\textbf{e}\\) is an \\(n\\)-dimensional vector of ones. \\(\\textbf{D}=\\text{diag}(c_1, \\dots, c_n)\\) is a diagonal matrix and \\(\\textbf{W}\\) is the win matrix introduced above.\nTo get a unique solution, PageRank requires a restriction on the scale of the strength vector. Therefore, the restriction that \\(\\textbf{p}\\) must to sum up to \\(n\\), i.e. \\(\\textbf{e}^T \\, \\textbf{p} = n\\), is introduced. This is the same as saying that the average strength is 1. Using this, the following holds: \\[ \\textbf{e} = \\frac{\\textbf{e} \\, \\textbf{e}^T \\, \\textbf{p}}{n}\\] Plugging this into the recursive formula for \\(\\textbf{p}\\) and factoring out \\(\\textbf{p}\\) on the right hand side yields: \\[ \\begin{align}\n\\textbf{p} &= \\left[ (1-d) \\, \\textbf{e} \\, \\textbf{e}^T/n + d \\, \\textbf{W} \\,\\textbf{D}_c^{-1} \\right] \\textbf{p} \\\\\n&= \\mathbf{A} \\, \\mathbf{p}\n\\end{align}\\]\nSo the PageRank strength vector is the eigenvector corresponding to an eigenvalue of 1 of matrix \\(\\textbf{A}\\). In fact, it can be shown that 1 is the largest eigenvalue of \\(\\textbf{A}\\). It is known that the power iteration (or Von Mises iteration) method converges to the eigenvector corresponding to the largest eigenvalue, in this case the eigenvector corresponding to the eigenvalue 1. So given some initial vector\\(\\textbf{p}_0\\), the PageRank strength vector can be calculated iteratively as: \\[\n\\begin{align}\n\\textbf{p}^{(t+1)} &\\gets \\textbf{A} \\, \\textbf{p}^{(t)} \\\\\n\\textbf{p}^{(t+1)} &\\gets \\frac{\\textbf{p}^{(t+1)}}{\\textbf{e}^T \\, \\textbf{p}^{(t+1)}} n\n\\end{align}\n\\] The second operation is a normalization ensuring that \\(\\textbf{e}^T \\, \\textbf{p}^{(t+1)} = n\\) Hastie et al. (2009)."
  },
  {
    "objectID": "blog/LearningToRank/LearningToRank.html#implementation-1",
    "href": "blog/LearningToRank/LearningToRank.html#implementation-1",
    "title": "Learning to Rank",
    "section": "Implementation",
    "text": "Implementation\nBelow, you can see my implementation of the PageRank approach.\n\nmy_pagerank &lt;- function(W, d=0.85, n_iter=1000){\n  n &lt;- dim(W)[1]\n  c &lt;- colSums(W)\n  A &lt;- (1-d)*rep(1,n) %*% t(rep(1,n))/n + d*W%*%diag(1/c)\n  \n  # initialize pagerank strength vector\n  # with all teams equally strong\n  p &lt;- rep(1/n, n)\n  names(p) &lt;- colnames(W)\n  \n  # power iteration\n  for (t in 1:n_iter) {\n    p &lt;- A%*%p\n    p &lt;- (p/sum(p))*n\n  }\n  \n  return(p)\n}\n\nLet’s apply my implementation of the PageRank to the win matrix.\n\nmy_pagerank_est &lt;- my_pagerank(W)\nhead(my_pagerank_est)\n\n                       [,1]\nArizona Cardinals 0.7385196\nAtlanta Falcons   1.2251638\nBaltimore Ravens  1.9602687\nBuffalo Bills     2.2841688\nCarolina Panthers 0.4254393\nChicago Bears     0.5206048\n\n\nAnd again I visualize the estimated strengths and the ranking using a horizontal bar char.\n\n\nShow code\ndf &lt;- data.frame(\n  team = rownames(my_pagerank_est),\n  score = as.numeric(my_pagerank_est)\n)\n\nggplot(df, aes(reorder(team, score), y=score)) +\n  geom_col(fill=\"#d72638\") +\n  coord_flip() +\n  labs(title=\"Ranking and Strength based on PageRank\",\n       y=\"Strength\",\n       x=\"Team\") +\n  theme_light()\n\n\n\n\n\n\n\n\n\nAs for the Bradley-Terry model, I want to compare my from-scratch implementation of PageRank to the one provided by the igraph R package. Before actually compute the PageRank strength, the igraph package requires to construct a graph using the transpose of the win matrix as adjacency matrix.\n\n# construct graph from tranpose of win matrix\ngraphObj &lt;- igraph::graph_from_adjacency_matrix(t(W), weighted = TRUE, mode = \"directed\")\n\n# run pagerank\npackage_pagerank_est &lt;- igraph::page_rank(graphObj)$vector\n\n# compare results\npagerank_compare &lt;- cbind(\"my_pagerank_est\"=my_pagerank_est, package_pagerank_est, \"ratio\"=my_pagerank_est/package_pagerank_est)\nhead(pagerank_compare)\n\n                            package_pagerank_est   \nArizona Cardinals 0.7385196           0.02307874 32\nAtlanta Falcons   1.2251638           0.03828637 32\nBaltimore Ravens  1.9602687           0.06125840 32\nBuffalo Bills     2.2841688           0.07138027 32\nCarolina Panthers 0.4254393           0.01329498 32\nChicago Bears     0.5206048           0.01626890 32\n\n\nObviously, my values and the values returned by the igraph package are not the same. However, when dividing them by each other it becomes apparent that my values are just 32 times the values returned by the package. The reason for the difference in scale is the following: The igraph package uses as restriction on the strength vector that it sums up to 1. However, I use as restriction that the strength vector sums up to \\(n=32\\). Importantly, this difference in scaling has no influence on the rankings."
  },
  {
    "objectID": "blog/SolvingODEsUsingANNs/SolvingODEsUsingANNs.html",
    "href": "blog/SolvingODEsUsingANNs/SolvingODEsUsingANNs.html",
    "title": "Neural Networks for Solving Ordinary Differential Equations",
    "section": "",
    "text": "In supervised learning settings, neural networks are employed to estimate conditional expectations or conditional probabilities. Some while ago, I read of a completely different application of neural networks. In fact, neural networks, can be used to numerically approximate the solutions of (ordinary) differential equations (Blechschmidt and Ernst 2021). Before implementing it from scratch in Python, I will first describe the setting and the general approach."
  },
  {
    "objectID": "blog/SolvingODEsUsingANNs/SolvingODEsUsingANNs.html#define-neural-network",
    "href": "blog/SolvingODEsUsingANNs/SolvingODEsUsingANNs.html#define-neural-network",
    "title": "Neural Networks for Solving Ordinary Differential Equations",
    "section": "Define Neural Network",
    "text": "Define Neural Network\nFirst, I define the neural network used for the approximation. It is a feed forward multilayer perceptron with one hidden layer that applies a \\(sigmoid\\) activation function between two fully connected linear layers.\n\nclass N(nn.Module):\n  def __init__(self, input_size, hidden_size, output_size):\n    super(N, self).__init__()\n    self.net = nn.Sequential(\n      nn.Linear(input_size, hidden_size),\n      nn.Sigmoid(),\n      nn.Linear(hidden_size, output_size)\n      )\n    \n  def forward(self, x):\n    return self.net(x)"
  },
  {
    "objectID": "blog/SolvingODEsUsingANNs/SolvingODEsUsingANNs.html#first-ode",
    "href": "blog/SolvingODEsUsingANNs/SolvingODEsUsingANNs.html#first-ode",
    "title": "Neural Networks for Solving Ordinary Differential Equations",
    "section": "First ODE",
    "text": "First ODE\nThe first example is an IVP consisting of a second order ODE given by: \\[ 4 u(x) + u^{(1)}(x) + u^{(2)}(x) = 0 \\] and initial conditions \\[ u(0) = 0.5, \\; u^{(1)}(0)=2 .\\]\n\nDefine Custom Loss Function\nThe custom loss function corresponding to the above IVP is computed as:\n\nclass Loss_IVP1(nn.Module):\n  def __init__(self):\n    super(Loss_IVP1, self).__init__()\n  \n  def forward(self, model, x):\n    x = x.clone().detach().requires_grad_(True)\n    u = model(x)\n    \n    # compute first derivative\n    du_dx = torch.autograd.grad(\n      outputs=u,\n      inputs=x,\n      grad_outputs=torch.ones_like(u),\n      create_graph=True\n      )[0]\n    \n    # compute second derivative\n    d2u_dx2 = torch.autograd.grad(\n      outputs=du_dx,\n      inputs=x,\n      grad_outputs=torch.ones_like(du_dx),\n      create_graph=True)[0]\n    \n    # compute loss function\n    loss_ODE = torch.mean((4*u + du_dx + d2u_dx2)**2)\n    loss_IC = (u[0] - 0.5)**2 + (du_dx[0] - 2)**2\n    loss_total = loss_ODE + loss_IC\n    \n    return loss_total\n\n\n\nConstruct Model, Loss and Optimizer\nTo ensure reproducibility of the subsequent steps, it is advisable to set a seed for the internal random number generator.\n\nseed = 42\ntorch.manual_seed(seed)\n\n&lt;torch._C.Generator at 0x1d461da3130&gt;\n\n\nI instantiate the neural network, the loss function to be minimized and the optimizer (here, I use Adam).\n\nmodel = N(input_size=1, hidden_size=10, output_size=1)\ncriterion = Loss_IVP1()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n\n\nSet x-values\nI decided to approximate the solution of the IVP on the interval \\(I=[0,5]\\). I choose \\(n=100\\) sample points evenly spread accross \\(I\\).\n\nx = torch.linspace(0, 5, 100)[:, None]\n\n\n\nTraining\nNow that all necessary components are set up, training can start.\n\nnum_epochs = 10\nsteps_per_epoch = 3000\n\nfor epoch in range(num_epochs):\n  for step in range(steps_per_epoch):\n    loss = criterion(model, x)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n\nEpoch [1/10], Loss: 0.1181\nEpoch [2/10], Loss: 0.0307\nEpoch [3/10], Loss: 0.0052\nEpoch [4/10], Loss: 0.0032\nEpoch [5/10], Loss: 0.0008\nEpoch [6/10], Loss: 0.0002\nEpoch [7/10], Loss: 0.0001\nEpoch [8/10], Loss: 0.0000\nEpoch [9/10], Loss: 0.0000\nEpoch [10/10], Loss: 0.0000\n\n\n\n\nVisualization\nOnce training is done, the learned, approximate solution can be compared to the analytical solution, which is known for this IVP. The analytical solution is given by: \\[ u(x) = e^{-0.5x} \\times \\left[ 0.5 \\times \\cos\\left(\\frac{\\sqrt{15}}{2} x \\right) + \\frac{3 \\sqrt{15}}{10} \\times \\sin \\left( \\frac{\\sqrt{15}}{2} x \\right) \\right] \\]\n\n\nShow code\nx = torch.linspace(0, 15, 1000)[:, None]\nwith torch.no_grad():\n  u = model(x)\n\nplt.figure(figsize=(6, 5))\nplt.plot(x, u, color=\"C3\", label=\"Neural Network\")\nplt.plot(x, torch.exp(-0.5*x)*(0.5*torch.cos(x*(15)**0.5/2)+3*((15)**0.5/10)*torch.sin(x*(15)**0.5/2)), color=\"C0\", label=\"Analytical\", linestyle=\"dotted\")\nplt.title(\"Solution of the IVP\")\nplt.xlabel(\"x\")\nplt.ylabel(\"u\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe above plot shows the approximate as well as the analytical solution. Apparently, on the chosen interval \\(I=[0,5]\\) the approximate solution matches the analytical solution. Outside of \\(I\\), the approximate solution deviates from the analytical one."
  },
  {
    "objectID": "blog/SolvingODEsUsingANNs/SolvingODEsUsingANNs.html#second-ode",
    "href": "blog/SolvingODEsUsingANNs/SolvingODEsUsingANNs.html#second-ode",
    "title": "Neural Networks for Solving Ordinary Differential Equations",
    "section": "Second ODE",
    "text": "Second ODE\nThe second example is an IVP that consists of the following first ODE \\[ u^{(1)}(x) - 2x (2-u) = 0 \\] and the initial condition \\[ u(0) = -1 .\\]\n\nDefine Custom Loss Function\nFor this IVP, the custom loss function is computed as:\n\nclass Loss_IVP2(nn.Module):\n  def __init__(self):\n    super(Loss_IVP2, self).__init__()\n  \n  def forward(self, model, x):\n    x = x.clone().detach().requires_grad_(True)\n    u = model(x)\n    \n    # compute first derivative\n    du_dx = torch.autograd.grad(\n      outputs=u,\n      inputs=x,\n      grad_outputs=torch.ones_like(u),\n      create_graph=True\n      )[0]\n    \n    # compute loss function\n    loss_DE = torch.mean((du_dx - 2*x*(2-u))**2)\n    loss_initial = (u[0] + 1)**2\n    loss_total = loss_DE + loss_initial\n    \n    return loss_total\n\n\n\nConstruct Model, Loss and Optimizer\nAgain, a seed is set for the internal random number generator.\n\nseed = 42\ntorch.manual_seed(seed)\n\n&lt;torch._C.Generator at 0x1d461da3130&gt;\n\n\nThe neural network, the loss function to be minimized and the optimizer are instantiated.\n\nmodel = N(input_size=1, hidden_size=10, output_size=1)\ncriterion = Loss_IVP2()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n\n\nSet x-values\nAs previously, the solution of the IVP is approximated on the interval \\(I=[0,5]\\) with \\(n=100\\) sample points evenly spread accross \\(I\\).\n\nx = torch.linspace(0, 5, 100)[:, None]\n\n\n\nTraining\nThe setup is finished and the training can begin.\n\nnum_epochs = 10\nsteps_per_epoch = 3000\n\nfor epoch in range(num_epochs):\n  for step in range(steps_per_epoch):\n    loss = criterion(model, x)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n\nEpoch [1/10], Loss: 0.3274\nEpoch [2/10], Loss: 0.0380\nEpoch [3/10], Loss: 0.0141\nEpoch [4/10], Loss: 0.0080\nEpoch [5/10], Loss: 0.0025\nEpoch [6/10], Loss: 0.0003\nEpoch [7/10], Loss: 0.0000\nEpoch [8/10], Loss: 0.0000\nEpoch [9/10], Loss: 0.0000\nEpoch [10/10], Loss: 0.0000\n\n\n\n\nVisualization\nFor this IVP, the analytical solution is given by: \\[ u(x) = 2 - 3 \\, e^{-x^2}. \\]\n\n\nShow code\nx = torch.linspace(-5, 5, 1000)[:, None]\nwith torch.no_grad():\n  u = model(x)\n\nplt.figure(figsize=(6, 5))\nplt.plot(x, u, color=\"C3\", label=\"Neural Network\")\nplt.plot(x, 2 - 3*torch.exp(-x**2), color=\"C0\" , label=\"Analytical\", linestyle=\"dotted\")\nplt.title(\"Solution of the IVP\")\nplt.xlabel(\"x\")\nplt.ylabel(\"u\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\nAlso for the second exemplary IVP, on the interval \\(I=[0,5]\\) the approximate solution closely aligns with the analytical solution, whereas outside of it both deviate."
  },
  {
    "objectID": "blog/post-1/index.html",
    "href": "blog/post-1/index.html",
    "title": "First Post",
    "section": "",
    "text": "Sed risus ultricies tristique nulla aliquet. Neque volutpat ac tincidunt vitae semper quis lectus nulla.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Enim sed faucibus turpis in eu mi bibendum neque. Ac orci phasellus egestas tellus rutrum tellus pellentesque eu. Velit sed ullamcorper morbi tincidunt ornare massa. Sagittis id consectetur purus ut faucibus pulvinar elementum integer. Tincidunt nunc pulvinar sapien et ligula ullamcorper malesuada proin libero. Lobortis feugiat vivamus at augue eget arcu. Aliquam ut porttitor leo a diam sollicitudin tempor id eu. Mauris a diam maecenas sed enim ut sem viverra aliquet. Enim ut tellus elementum sagittis vitae et leo duis. Molestie at elementum eu facilisis sed odio morbi quis commodo. Sapien pellentesque habitant morbi tristique senectus. Quam vulputate dignissim suspendisse in est. Nulla pellentesque dignissim enim sit amet venenatis urna cursus eget.\nVelit aliquet sagittis id consectetur purus ut faucibus pulvinar elementum. Viverra mauris in aliquam sem fringilla ut morbi tincidunt augue. Tortor at auctor urna nunc id. Sit amet consectetur adipiscing elit duis tristique sollicitudin. Aliquet nibh praesent tristique magna sit amet purus. Tristique senectus et netus et malesuada fames ac turpis. Hac habitasse platea dictumst quisque. Auctor neque vitae tempus quam pellentesque nec nam aliquam. Ultrices tincidunt arcu non sodales neque sodales ut etiam. Iaculis at erat pellentesque adipiscing. Cras tincidunt lobortis feugiat vivamus. Nisi est sit amet facilisis magna etiam. Pharetra pharetra massa massa ultricies mi quis hendrerit. Vitae sapien pellentesque habitant morbi tristique senectus. Ornare aenean euismod elementum nisi quis eleifend quam adipiscing vitae."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Neural Networks for Probability Density Estimation\n\n\nI implement from scratch an approach for estimating an unknown probability density function of a sample using neural networks. To demonstrate that this method works, I apply it to two examples.\n\n\n\n\n\nOct 7, 2025\n\n\nDominik G. Eichhorn\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks for Solving Ordinary Differential Equations\n\n\nI code from scratch a neural network based approach for numerically solving ordinary differential equations (ODE). I illustrate how this method functions by applying it to two examplary ODEs.\n\n\n\n\n\nSep 10, 2025\n\n\nDominik G. Eichhorn\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Rank\n\n\nI implement from scratch two approaches for learning a ranking from imcomplete pairwise comparison data (Bradley-Terry model and PageRank). Then, I apply them to NFL data and compare the results.\n\n\n\n\n\nAug 21, 2025\n\n\nDominik G. Eichhorn\n\n\n\n\n\n\n\n\n\n\n\n\nOffline Reinforcement Learning for Dynamic Pricing\n\n\nTO DO\n\n\n\n\n\nJul 17, 2025\n\n\nDominik G. Eichhorn\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning for Managing Stock Portfolios\n\n\nTO DO\n\n\n\n\n\nMay 1, 2022\n\n\nDominik G. Eichhorn\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html",
    "href": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html",
    "title": "Neural Networks for Probability Density Estimation",
    "section": "",
    "text": "The impressive capabilitis of neural networks in typical regression and classification tasks are widely known. Recently, I came across a paper about a lesser known but statistically very interesting application of neural networks that was written some years ago. The paper shows how neural networks can be used for estimating the probability density function of a random variable (Magdon-Ismail and Atiya 1998). Before implementing it from scratch in Python, I will first describe the general approach."
  },
  {
    "objectID": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html#define-neural-network",
    "href": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html#define-neural-network",
    "title": "Neural Networks for Probability Density Estimation",
    "section": "Define Neural Network",
    "text": "Define Neural Network\nAt first, I define the neural network used for approximating the CDF. It is a fully connected feed forward neural network with one hidden layer using a \\(tanh\\) activation function and an output layer using a \\(sigmoid\\) activation function. Thereby, the neural network is differentiable and maps \\(\\mathbb{R}\\) onto the interval \\((0,1)\\).\n\nclass N(nn.Module):\n  def __init__(self, input_size, hidden_size, output_size):\n    super(N, self).__init__()\n    self.net = nn.Sequential(\n      nn.Linear(input_size, hidden_size),\n      nn.Tanh(),\n      nn.Linear(hidden_size, output_size),\n      nn.Sigmoid()\n      )\n    \n  def forward(self, x):\n    return self.net(x)"
  },
  {
    "objectID": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html#define-modified-loss-function",
    "href": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html#define-modified-loss-function",
    "title": "Neural Networks for Probability Density Estimation",
    "section": "Define Modified Loss Function",
    "text": "Define Modified Loss Function\nNext, I define the modified loss function as described above.\n\nclass Loss(nn.Module):\n  def __init__(self):\n    super(Loss, self).__init__()\n  \n  def forward(self, y_pred, y_true, lambda_mon, mon_l, mon_u):\n    loss_dist = torch.mean((y_pred - y_true)**2)\n    \n    diff = mon_l - mon_u\n    loss_mon = torch.mean(torch.clamp(diff, min=0))\n    \n    loss_total = loss_dist + lambda_mon*loss_mon\n    \n    return loss_total"
  },
  {
    "objectID": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html#gaussian-mixture",
    "href": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html#gaussian-mixture",
    "title": "Neural Networks for Probability Density Estimation",
    "section": "Gaussian Mixture",
    "text": "Gaussian Mixture\nFor the first example, realizations will be drawn from a 2-component Gaussian mixture distribution. So I construct one with mixture weights \\(\\phi_1=0.2\\) and \\(\\phi_2=0.8\\), expectations \\(\\mu_1=2\\) and \\(\\mu_2=5\\) and standard deviations \\(\\sigma_1=0.25\\) and \\(\\sigma_2=0.5\\).\n\n# construct 2-component Gaussian mixture distribution\ncomp1 = stats.Normal(mu=2, sigma=0.25)\ncomp2 = stats.Normal(mu=5, sigma=0.5)\nmix = stats.Mixture([comp1, comp2], weights=[0.2, 0.8])\n\nThe corresponding PDF looks as follows:\n\n\nShow code\nx = np.linspace(0, 10, 1000)\n\nplt.figure(figsize=(6,5))\nplt.plot(x, mix.pdf(x), color=\"C0\", linestyle=\"dotted\")\nplt.title(\"True Probability Density Function\")\nplt.xlabel(\"x\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSet Seed\nIn the subsequent steps, the neural network will be initialized and realizations will be sampled from the PDF given above. Both involves randomness. Therefore, to ensure reproducibility of the subsequent steps, one must set a seed for the random number generators.\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\n&lt;torch._C.Generator at 0x1e0c59be7b0&gt;\n\n\n\n\nConstruct Model, Loss and Optimizer\nAfter that, I instantiate the neural network, the loss function to be minimized and the optimizer (here, I use Adam).\n\nmodel = N(input_size=1, hidden_size=10, output_size=1)\ncriterion = Loss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n\n\nSample from PDF\nNext, I sample \\(n=200\\) i.i.d. realizations from the 2-component Gaussian mixture distribution. Subsequently, I sort then in ascending order.\n\n# sample data, sort it and convert to torch tensor\nn = 200\nrng = np.random.default_rng(seed)\nx = mix.sample(n, rng=rng)\nx = torch.from_numpy(np.sort(x)).float().unsqueeze(1)\n\n\n\nSet Monotonicity Points\nBefore training can start, I have to specify \\(\\lambda_{mon}\\), \\(n_{mon}\\), the monotonicity points themselves as well as \\(\\Delta\\). I choose to place \\(n_{mon}=1000\\) monotonicity points equally spaced between the smallest and the largest sampled \\(X\\)-values.\n\n# set monotonicity points\nlambda_mon = 1e6\nn_mon = 1000\nmon_points = torch.linspace(x[0,0], x[-1,0], n_mon)[:, None]\ndelta = 0.1*(max(x)-min(x))/n_mon\n\n\n\nTraining\nNow, everything is set up and training can start. Observe that, as described in the general approach, in each iteration, a new set of \\(n\\) samples are drawn i.i.d. from \\(\\mathcal{U}(0,1)\\) and sorted in ascending order. These serve as targets only for that iteration.\n\nnum_epochs = 100\nsteps_per_epoch = 2500\n\nfor epoch in range(num_epochs):\n  for step in range(steps_per_epoch):\n    preds = model(x)\n    \n    u = np.random.uniform(0, 1, n)\n    u = torch.from_numpy(np.sort(u)).float().unsqueeze(1)\n    \n    mon_l = model(mon_points)\n    mon_u = model(mon_points + delta)\n    \n    loss = criterion(preds, u, lambda_mon, mon_l, mon_u)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\", end=\"\\r\", flush=True)\n\n\n\nPlot CDF\nOnce training has finished, I plot the learned neural network approximation of CDF against the actual CDF of the 2-component Gaussian mixture.\n\n\nShow code\nxx = torch.linspace(0, 10, 1000).unsqueeze(1)\nwith torch.no_grad():\n    cdf_est = model(xx)\n\nplt.figure(figsize=(6, 5))\nplt.plot(xx.numpy(), cdf_est.numpy(), color=\"C3\", label=\"Estimated CDF\")\nplt.plot(xx.numpy(), mix.cdf(xx), color=\"C0\", label=\"True CDF\", linestyle=\"dotted\")\nplt.title(\"Cumulative Density Function (CDF)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"Cumulative Density\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nObviously, the neural network approximation of the CDF given just a sample of 200 realizations of \\(X\\) is very accurate.\n\n\nCompute PDF\nGiven the neural network approximation of the CDF, the following function computes an estimate of the PDF from it.\n\ndef ComputePDF(model, x):\n  x = x.requires_grad_(True)\n  cdf = model(x)\n  grad_outputs = torch.ones_like(cdf)\n  pdf = torch.autograd.grad(\n    outputs=cdf,\n    inputs=x,\n    grad_outputs=grad_outputs\n    )[0]\n  return pdf\n\n\n\nPlot PDF\nThis plot confirms, that the estimate of the PDF obtained from the neural network approximation to the CDF is quite precise.\n\n\nShow code\npdf_est = ComputePDF(model, xx).detach()\nxx_np = xx.detach().numpy()\n\n\nplt.figure(figsize=(6, 5))\nplt.plot(xx_np, pdf_est.numpy(), color=\"C3\", label=\"Estimated PDF\")\nplt.plot(xx_np, mix.pdf(xx_np), color=\"C0\", label=\"True PDF\", linestyle=\"dotted\")\nplt.title(\"Probability Density Function (PDF)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html#weibull-distribution",
    "href": "blog/ANNsForProbabilityDensityEstimation/ANNsForProbabilityDensityEstimation.html#weibull-distribution",
    "title": "Neural Networks for Probability Density Estimation",
    "section": "Weibull Distribution",
    "text": "Weibull Distribution\nAs second example, I will use a Weibull distribution with \\(shape=1.8\\) (and \\(scale=1\\)).\n\n# construct Weibull distribution\ndist = stats.weibull_min(c=1.8)\n\nA plot of its PDF shows that it is clearly skewed.\n\n\nShow code\nx = np.linspace(0, 5, 1000)\n\nplt.figure(figsize=(6,5))\nplt.plot(x, dist.pdf(x), color=\"C0\", linestyle=\"dotted\")\nplt.title(\"True Probability Density Function\")\nplt.xlabel(\"x\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\n\nThe following steps (set seed; construct model, loss and optimizer; sample from PDF; set monontonicity points; training) are analogous to those in the first example. Therefore, I hide that part of the code. If you wish to have a look at it, click on the “Show code” button below.\n\n\nShow code\n# set seed\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\n# construct model, loss and optimizer\nmodel = N(input_size=1, hidden_size=10, output_size=1)\ncriterion = Loss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# sample data, sort it and convert to torch tensor\nn = 200\nrng = np.random.default_rng(seed)\nx = dist.rvs(n, random_state=rng)\nx = torch.from_numpy(np.sort(x)).float().unsqueeze(1)\n\n# set monotonicity points\nlambda_mon = 1e6\nn_mon = 1000\nmon_points = torch.linspace(x[0,0], x[-1,0], n_mon)[:, None]\ndelta = 0.1*(max(x)-min(x))/n_mon\n\n\nnum_epochs = 100\nsteps_per_epoch = 2500\n\n# training\nfor epoch in range(num_epochs):\n  for step in range(steps_per_epoch):\n    preds = model(x)\n    \n    u = np.random.uniform(0, 1, n)\n    u = torch.from_numpy(np.sort(u)).float().unsqueeze(1)\n    \n    mon_l = model(mon_points)\n    mon_u = model(mon_points + delta)\n    \n    loss = criterion(preds, u, lambda_mon, mon_l, mon_u)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\", end=\"\\r\", flush=True)\n\n\n\nPlot CDF\nInspecting the below plot of the learned neural network approximation of the CDF and the actual CDF shows again that the neural network was successful in recovering the actual CDF.\n\n\nShow code\nxx = torch.linspace(0, 5, 1000).unsqueeze(1)\nwith torch.no_grad():\n    cdf_est = model(xx)\n\nplt.figure(figsize=(6, 5))\nplt.plot(xx.numpy(), cdf_est.numpy(), color=\"C3\", label=\"Estimated CDF\")\nplt.plot(xx.numpy(), dist.cdf(xx), color=\"C0\", label=\"True CDF\", linestyle=\"dotted\")\nplt.title(\"Cumulative Density Function (CDF)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"Cumulative Density\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPlot PDF\nAlso when comparing the resulting estimated PDF to the actual one, it seems that neural network approach yields good results.\n\n\nShow code\npdf_est = ComputePDF(model, xx).detach()\nxx_np = xx.detach().numpy()\n\n\nplt.figure(figsize=(6, 5))\nplt.plot(xx_np, pdf_est.numpy(), color=\"C3\", label=\"Estimated PDF\")\nplt.plot(xx_np, dist.pdf(xx_np), color=\"C0\", label=\"True PDF\", linestyle=\"dotted\")\nplt.title(\"Probability Density Function (PDF)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "blog/CopulasForFF5Factors/CopulasForFF5Factors.html",
    "href": "blog/CopulasForFF5Factors/CopulasForFF5Factors.html",
    "title": "Dominik G. Eichhorn",
    "section": "",
    "text": "Gute Literatur mit Step-by-Step Vorgehen für Real Life Data:\nDaten können unter diesem Link downgeloaded werden: “https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_CSV.zip”\n\ngetwd()\n\n[1] \"C:/Users/domin/Documents/PersonalWebsite/dgeichhorn.github.io/blog/CopulasForFF5Factors\"\n\nlibrary(readr)\ndt &lt;- read_csv(\"F-F_Research_Data_5_Factors_2x3.csv\",\n               skip = 4, n_max = 743,\n               col_names = c(\"Date\", \"Mkt_RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\", \"RF\"))\n\nRows: 743 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (7): Date, Mkt_RF, SMB, HML, RMW, CMA, RF\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nView(dt)\n\ncor_matrix &lt;- cor(dt[, c(\"Mkt_RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\")])\nprint(cor_matrix)\n\n           Mkt_RF          SMB          HML          RMW          CMA\nMkt_RF  1.0000000  0.277162682 -0.205902792 -0.186881612 -0.353833434\nSMB     0.2771627  1.000000000  0.006444189 -0.348613074 -0.087387014\nHML    -0.2059028  0.006444189  1.000000000  0.085160500  0.682067617\nRMW    -0.1868816 -0.348613074  0.085160500  1.000000000 -0.003665752\nCMA    -0.3538334 -0.087387014  0.682067617 -0.003665752  1.000000000\n\nplot(dt$HML, dt$CMA)"
  },
  {
    "objectID": "blog/LibrariesInUK/LibrariesInUK.html",
    "href": "blog/LibrariesInUK/LibrariesInUK.html",
    "title": "Dominik G. Eichhorn",
    "section": "",
    "text": "Idea für eine Data Viz Post: - map plot: nutzung von libraries; vermeintliche einfach erklärung: in manchen districts sind mehr doofis die weniger in bibs gehen ABER: Nutzung hängt auch von Erreichbarkeit ab - map plot: erreichbarkeit von libraries - scatterplot: zusammenhang nutzung vs. erreichbarkeit - korrektur: (perc usage)/(perc 30 min walk erreichbar)\nLink für Plotting/Creating Maps in R: “https://datatricks.co.uk/creating-maps-in-r-2019”\nDaten: - Nutzung von Libraries: https://www.ons.gov.uk/explore-local-statistics/indicators/visited-a-public-library - Erreichbarkeit von Libraries: https://www.ons.gov.uk/explore-local-statistics/indicators/library-walk\nTo create a UK map heatmap at the Lower Tier Local Authority (LTLA / Unitary Authority) level with ggplot2, you’ll need:\nA shapefile (or geojson) of UK local authorities (LTLA/UA level).\nA dataset with values you want to plot (e.g., rates, counts, etc.), keyed by local authority code (e.g., lad22cd from ONS).\nJoining the shapefile with your data and plotting via geom_sf().\nHere’s a reproducible example in R:\n\n# Install if needed\n# install.packages(c(\"sf\", \"ggplot2\", \"dplyr\"))\n\n# library(sf)\n# library(ggplot2)\n# library(dplyr)\n# \n# # --- Step 1: Load UK Local Authority boundaries (ONS Geoportal provides shapefiles) ---\n# # Example: use Local Authority Districts (2022) boundaries (generalised, clipped)\n# # Download from: https://geoportal.statistics.gov.uk/\n# shapefile &lt;- \"Local_Authority_Districts_(December_2022)_UK_BUC.shp\"\n# uk_lad &lt;- st_read(shapefile)\n# \n# # Inspect codes\n# head(uk_lad)\n# \n# # --- Step 2: Example data ---\n# # Suppose you have some variable for each LAD code\n# set.seed(123)\n# example_data &lt;- data.frame(\n#   lad22cd = uk_lad$LAD22CD, # local authority codes\n#   value = runif(nrow(uk_lad), 0, 100) # random values\n# )\n# \n# # --- Step 3: Join shapefile with data ---\n# uk_map &lt;- uk_lad %&gt;%\n#   left_join(example_data, by = c(\"LAD22CD\" = \"lad22cd\"))\n# \n# # --- Step 4: Plot heatmap ---\n# ggplot(uk_map) +\n#   geom_sf(aes(fill = value), colour = NA) +\n#   scale_fill_viridis_c(option = \"plasma\") +\n#   theme_minimal() +\n#   labs(title = \"Example Heatmap by UK Local Authority\",\n#        fill = \"Value\")"
  },
  {
    "objectID": "blog/post-2/index.html",
    "href": "blog/post-2/index.html",
    "title": "Second Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Quis imperdiet massa tincidunt nunc pulvinar sapien et ligula. Amet cursus sit amet dictum sit amet. Eget duis at tellus at urna condimentum. Convallis aenean et tortor at risus viverra. Tincidunt ornare massa eget egestas purus viverra accumsan. Et malesuada fames ac turpis egestas. At imperdiet dui accumsan sit amet. Ut ornare lectus sit amet est placerat. Enim nulla aliquet porttitor lacus luctus accumsan tortor posuere. Duis ultricies lacus sed turpis tincidunt id aliquet risus. Mattis enim ut tellus elementum sagittis. Dui id ornare arcu odio ut. Natoque penatibus et magnis dis. Libero justo laoreet sit amet cursus sit. Sed faucibus turpis in eu. Tempus iaculis urna id volutpat lacus laoreet.\nPhasellus vestibulum lorem sed risus. Eget felis eget nunc lobortis mattis. Sit amet aliquam id diam maecenas ultricies. Egestas maecenas pharetra convallis posuere morbi. Etiam erat velit scelerisque in dictum non consectetur a erat. Cras fermentum odio eu feugiat pretium nibh ipsum consequat. Viverra accumsan in nisl nisi scelerisque. Et netus et malesuada fames ac. Amet tellus cras adipiscing enim eu turpis egestas pretium aenean. Eget lorem dolor sed viverra ipsum nunc aliquet. Ultrices dui sapien eget mi proin sed libero enim sed. Ultricies mi eget mauris pharetra et ultrices neque. Ipsum suspendisse ultrices gravida dictum. A arcu cursus vitae congue mauris rhoncus aenean vel. Gravida arcu ac tortor dignissim convallis. Nulla posuere sollicitudin aliquam ultrices."
  },
  {
    "objectID": "blog/LearningToRank/LearningToRank.html",
    "href": "blog/LearningToRank/LearningToRank.html",
    "title": "Learning to Rank",
    "section": "",
    "text": "Probably everyone is familiar with those tables in sports that rank teams, usually according to the number of games won. This seems to be a valide approach for tournaments where every team plays against every other team the same number of times. Such tournaments are called robin-round tournaments and examples include the Premier League as well as the Fußball and the Handball Bundesliga. Robin-round tournaments are a special type of complete comparisons.\nHowever, there are also tournaments in which not every team plays against every other team, i.e. incomplete comparisons. Examples include the NFL in American Football or knock-out tournaments such as playoffs or cups. In such tournaments, some teams might face on average stronger opponents than other teams. Therefore, the number of wins may not reflect the true strength of a team and may not be used to rank teams. Instead, it becomes important, how strong the opponents were, against which a team won or lost.\nSo I was wondering, what approaches there are for learning a ranking from data on the outcome of incomplete pairwise comparisons. Note that this problem does not just arise in sports but in a variety of other domains. For instance, in preference modelling, multiple individuals must choose between different pairs of items. Based on the outcomes, one tries to rank all of the items. Nevertheless, I will stick to the application in sports.\nI found among others two interesting approaches: the PageRank algorithm and the Bradley-Terry model. I will implement both from scratch in R after having shortly described them. Furthermore, I will compare the results of my own implementation to the ones returned by dedicated libraries. For illustration, I will use data on the outcome of every NFL game played during the 2024-2025 regular season."
  },
  {
    "objectID": "blog/MLforAssetManagement/MLforAssetManagement.html",
    "href": "blog/MLforAssetManagement/MLforAssetManagement.html",
    "title": "Machine Learning for Managing Stock Portfolios",
    "section": "",
    "text": "Before Diving In\nThose interested in the technical details may scroll down to the bottom (section Appendix), where the pdf-file of my master’s thesis is displayed. Unlike the other posts, in the remainder of this post, I will not go into the technical details or show any code. I will rather give an high-level overview of what I did as part of my master’s thesis.\n\n\nIntroduction\nIn their seminal paper, Gu, Kelly, and Xiu (2020) describe how supervised machine learning models can be utilized to manage stock portfolios. They report that empirically these so-called machine learning portfolios deliver substantial risk-adjusted outperformance. However, their analyses only consider gross returns, i.e., before transaction costs. This is a problem insofar as these machine learning portfolios very frequently buy stocks and sell them shortly afterwards (or the other way around). Each of these stock-level transactions leads to costs which reduce the net returns of the portfolio. It is therefore a fair question what the net return of these machine learning portfolios is.\nIn trying to answer this question, I encountered two major challenges. First, Gu, Kelly, and Xiu (2020) do not provide any code for the construction of the machine learning portfolios. Hence, I had to replicate their approach from scratch in Python based on the descriptions in their paper. Second, in order to calculate the net returns I need at every point in time the stock-level transaction costs for all stocks considered (or at least an estimate of them). My supervisor pointed out to me that such a data set had recently been made publicly available by Chen and Zimmermann (2021), which I then used for my analyses.\nIn the following, I will first briefly say something about the data set I used. Then, I will give a high-level description of how I constructed the machine learning portfolios. Subsequently, I will present my results on their after-transaction-cost performance.\n\n\nData\nThe data, upon which my analyses were based, covered monthly information on approx. 8,000 major US exchanged-listed stocks between 1970 and 2017. For every stock, I have for each month a set of 202 stock/firm specific characteristics, its gross return as well as its transaction/trading cost (i.e. half the spread).\n\n\nApproach\nThe foundation upon which machine learning portfolios are based is a prediction model. The prediction model takes the characteristics of each stock in month \\(t\\) as input and outputs for each stock a prediction of the gross return realized in month \\(t+1\\). The prediction model is gradually updated overtime using an expanding window approach.\nI trained and tuned a broad variety of prediction models. These include several baseline unpenalized and penalized linear models, tree based models such as random forests and gradient boosted trees, and multiple deep learning models. Note that each prediction model is the foundation for a different machine learning portfolio.\nGiven a prediction model, at the end of month \\(t\\), the machine learning portfolio is constructed as follows: The prediction model is used to predict the gross return of each stock in month \\(t+1\\). Next, all stocks are sorted according to their predicted gross return for month \\(t+1\\). Subsequently, the portfolio is formed by going long in the top decile and going short the bottom decile of stocks sorted by predicted return.\nNote that at any point in time, 80% of the stocks are kept neutral (zero position).\nführt zu großen turnovers weil selten ein stock 2 monate hintereinander in top10 or bottom10 bleibt\nstattdessen of so dass von long oder short in neutral position oder sogar in opposite position; das alles fürhrt zu transaction costs welche\nda wir datensatz mit stock specific transaction costs haben können wir jetzt schauen was die net returns sind\n\n\nResults\n\n\nAppendix\n\n\n\n\n\n\nReferences\n\nChen, Andrew Y, and Tom Zimmermann. 2021. “Open Source Cross-Sectional Asset Pricing.” Critical Finance Review, Forthcoming.\n\n\nGu, Shihao, Bryan Kelly, and Dacheng Xiu. 2020. “Empirical Asset Pricing via Machine Learning.” The Review of Financial Studies 33 (5): 2223–73."
  },
  {
    "objectID": "blog/MLforAssetManagement/MLforAssetManagement.html#approach",
    "href": "blog/MLforAssetManagement/MLforAssetManagement.html#approach",
    "title": "Machine Learning for Managing Stock Portfolios",
    "section": "Approach",
    "text": "Approach\nUnder the Bradley-Terry model, the probability that in a direct comparison team \\(i\\) would beat team \\(j\\) is given by: \\[ P(\\text{\"i beats j\"}) = \\frac{\\theta_i}{\\theta_i + \\theta_j}\\] for \\(i,j = 1, \\dots, n, i \\neq j\\). \\(\\theta_i\\) can be thought of as measuring the strength of team \\(i\\). Ceteris paribus, the greater \\(\\theta_i\\), the greater the probability that team \\(i\\) wins against any other team.\nUnder independence, the likelihood function (i.e. the probability of the observed data under \\(\\theta_1, \\dots, \\theta_n\\)) is \\[L(\\theta_1, \\dots, \\theta_n) =  \\prod_{i=1}^n \\prod_{j=1}^n \\left(\\frac{\\theta_i}{\\theta_i + \\theta_j}\\right)^{w_{ij}}.\n\\] Note that \\(w_{ii}\\) is set to 0 as mentioned above. The log-likelihood function is \\[ l(\\theta_1, \\dots, \\theta_n) = \\sum_{i=1}^n \\sum_{j=1}^n w_{ij} \\ln(\\theta_i) - \\sum_{i=1}^n \\sum_{j=1}^n w_{ij} \\ln(\\theta_i + \\theta_j)\\] The maximum likelihood estimates (MLEs) are obtained by maximizing \\(l\\) w.r.t. \\(\\theta_1, \\dots, \\theta_n\\). For this purpose the gradient of \\(l\\) is required. It is given by: \\[ \\begin{align} \\frac{\\partial l}{\\partial \\theta_k}(\\theta_1, \\dots, \\theta_n) &= \\frac{1}{\\theta_k} \\sum_{j=1}^n w_{kj} - \\left[ \\overbrace{ \\sum_{i=1}^n \\frac{w_{ik}}{\\theta_i + \\theta_k}}^{\\text{case: }j=k} + \\overbrace{\\sum_{j=1}^n \\frac{w_{kj}}{\\theta_k + \\theta_j}}^{\\text{case: }i=k} \\right], \\\\\n&= \\frac{1}{\\theta_k} \\sum_{j=1}^n w_{kj} - \\left[ \\sum_{j=1}^n \\frac{w_{jk}}{\\theta_j + \\theta_k} + \\sum_{j=1}^n \\frac{w_{kj}}{\\theta_k + \\theta_j} \\right],\\\\\n&= \\frac{1}{\\theta_k} \\sum_{j=1}^n w_{kj} - \\sum_{j=1}^n \\frac{w_{jk} +w_{kj}}{\\theta_j + \\theta_k} ,  &\\forall k=1,\\dots n \\end{align}\\] Note that I index the differentiation variable by \\(k\\) in order to clearly separate it from the summation index \\(i\\). Setting the gradient equal to 0 and rearranging yields: \\[ \\theta_k = \\frac{\\sum_{j=1}^n w_{kj}}{\\sum_{j=1}^n \\frac{w_{kj} + w_{jk}}{\\theta_k + \\theta_j}}, \\; \\forall k=1,\\dots,n \\] Starting with some initial values \\(\\theta_1^{(0)}, \\dots, \\theta_k^{(0)}\\), and using the above equation, the MLEs are iteratively obtained as follows: \\[\\begin{align}\n\\theta_k^{(t+1)} &\\gets \\frac{\\sum_{j=1}^n w_{kj}}{\\sum_{j=1}^n \\frac{w_{kj} + w_{jk}}{\\theta_k^{(t)} + \\theta_j^{(t)}}}, &\\; \\forall k=1,\\dots,n \\\\\n\\theta_k^{(t+1)} &\\gets \\frac{1}{\\left(\\prod_{j=1}^n \\theta_j^{(t+1)} \\right)^{1/n}}, &\\; \\forall k=1,\\dots,n\n\\end{align}\\] The second operation normalizes the MLEs such that their geometric mean is 1 (Newman 2023)."
  },
  {
    "objectID": "blog/MLforAssetManagement/MLforAssetManagement.html#implementation",
    "href": "blog/MLforAssetManagement/MLforAssetManagement.html#implementation",
    "title": "Machine Learning for Managing Stock Portfolios",
    "section": "Implementation",
    "text": "Implementation\nHaving outlined how the MLEs are obtained in the Bradley-Terry model, below, you find my from-scratch implementation of it.\n\nmy_bradleyterry &lt;- function(W, n_iter=1000){\n  n &lt;- dim(W)[1]\n  \n  # initialize strength vector theta,\n  # before and after update,\n  # with all teams equally strong\n  theta.old &lt;- rep(1, n)\n  names(theta.old) &lt;- colnames(W)\n  theta.new &lt;- rep(1,n)\n  names(theta.new) &lt;- colnames(W)\n  \n  for (t in 1:n_iter) {\n    for (i in 1:n) {\n      theta.new[i]&lt;-sum(W[i,])/(sum((W[i,]+W[,i])/(theta.old[i]+theta.old )))\n    }\n    \n    # normalize by geomtric mean\n    theta.new &lt;- theta.new/prod(theta.new)^(1/n)\n    \n    # update\n    theta.old &lt;- theta.new\n  }\n  \n  return(theta.new)\n}\n\nI apply my function for computing the MLEs to the winning matrix of the 2024-2025 regular season retrieved above.\n\nmy_btm_mles &lt;- my_bradleyterry(W)\nhead(my_btm_mles)\n\nArizona Cardinals   Atlanta Falcons  Baltimore Ravens     Buffalo Bills \n        1.0972960         0.9883723         3.4372074         3.5989702 \nCarolina Panthers     Chicago Bears \n        0.3647306         0.4153262 \n\n\nNext, I sort the teams in descending order according to their estimated strengths and construct a horizontal bar char.\n\n\nShow code\nlibrary(ggplot2)      # for visualization\n\ndf &lt;- data.frame(\n  team = names(my_btm_mles),\n  score = as.numeric(my_btm_mles)\n)\n\np &lt;- ggplot(df, aes(reorder(team, score), y=score)) +\n  geom_col(fill=\"#0b0b64\") +\n  coord_flip() +\n  labs(title=\"Ranking and Strength based on Bradley-Terry\",\n       y=\"Strength\",\n       x=\"Team\") +\n  theme_light()\n\nggsave(\"cover.jpg\", plot = p, width = 8, height = 6, dpi = 300, bg = \"white\")\n\np\n\n\n\n\n\n\n\n\n\nNow, let’s compare the results of my from-scratch implementation to those of the BradleyTerry2 R package.\n\n# use built-in function to convert W in format required by BradleyTerry2\ndt &lt;- BradleyTerry2::countsToBinomial(W)\n\n# fit Bradley-Terry model using BradleyTerry2\npackage_btm &lt;- BradleyTerry2::BTm(cbind(win1, win2), player1, player2, data=dt)\n\n# extract Bradley-Terry model MLEs\npackage_btm_mles &lt;- BradleyTerry2::BTabilities(package_btm)\n\n\n# compare results\nbtm_compare &lt;- cbind(my_btm_mles, \"package_btm_mles\"=package_btm_mles[,\"ability\"])\nhead(btm_compare)\n\n                  my_btm_mles package_btm_mles\nArizona Cardinals   1.0972960        0.0000000\nAtlanta Falcons     0.9883723       -0.1045449\nBaltimore Ravens    3.4372074        1.1418104\nBuffalo Bills       3.5989702        1.1877988\nCarolina Panthers   0.3647306       -1.1014454\nChicago Bears       0.4153262       -0.9715400\n\n\nAt first sight, it seems that the results returned by the BradleyTerry2 package and my results differ quite alot. Therefore, I had a closer look at the documentation of the BradleyTerry2 package. I found out that they utilize a slightly different specification of the Bradley-Terry model (let’s call it the exponential specification). However, both specifications are equivalent in the sense that, first, both result in the same winning probabilities and, second, that there is an explicit formula for converting their parameters.\nThe exponential specification is given by: \\[P(\\text{\"i beats j\"}) = \\frac{e^{s_i}}{e^{s_i} + e^{s_j}}, \\; \\forall i,j=1,\\dots, n\\] and \\(s_0\\) is set to be 0. The formulas for converting the parameters of the two specifications are: \\[ \\begin{align} s_i = \\ln \\left(\\frac{\\theta_i}{\\theta_0}\\right), \\\\\n\\theta_i = \\exp(s_i) \\times \\theta_0\n\\end{align}\\] So, let’s now convert the parameters I estimated into the format of the exponential specification and then compare it to the output of the BradleyTerry2 package.\n\n\n# compare results\nmy_conv_btm_mles &lt;- log(my_btm_mles/my_btm_mles[1])\nbtm_compare &lt;- cbind(my_btm_mles, my_conv_btm_mles, \"package_btm_mles\"=package_btm_mles[,\"ability\"])\n\n\n# compute Euclidean distance between my_conv_btm_mles and package_btm_mles\ndist &lt;- sqrt(sum((btm_compare[,2]-btm_compare[,3])^2))\nprint(paste(\"Euclidean distance between my_conv_btm_mles and package_btm_mles:\", dist))\n\n[1] \"Euclidean distance between my_conv_btm_mles and package_btm_mles: 5.39456400516441e-12\"\n\nhead(btm_compare)\n\n                  my_btm_mles my_conv_btm_mles package_btm_mles\nArizona Cardinals   1.0972960        0.0000000        0.0000000\nAtlanta Falcons     0.9883723       -0.1045449       -0.1045449\nBaltimore Ravens    3.4372074        1.1418104        1.1418104\nBuffalo Bills       3.5989702        1.1877988        1.1877988\nCarolina Panthers   0.3647306       -1.1014454       -1.1014454\nChicago Bears       0.4153262       -0.9715400       -0.9715400\n\n\nAfter converting my MLEs, they are exactly the same as the MLEs returned by the BradleyTerry2 package."
  },
  {
    "objectID": "blog/MLforAssetManagement/MLforAssetManagement.html#approach-1",
    "href": "blog/MLforAssetManagement/MLforAssetManagement.html#approach-1",
    "title": "Machine Learning for Managing Stock Portfolios",
    "section": "Approach",
    "text": "Approach\nPageRank does not treat all of the opponents of a given team equally. In fact, it accounts for both, the strength of the opponents as well as their total number of games lost. Opponents with higher strength get more weight, while opponents with a higher total number of games lost get a less weight.\nBased on this mechanism, the strength of team \\(i\\) according to PageRank, \\(p_i\\), is recursively defined as: \\[ p_i = (1-d) + d \\sum_{j=1}^n \\left( \\frac{w_{ij}}{c_j} \\right) p_j \\] As before, \\(w_{ij}\\) is the number of times team \\(i\\) won against team \\(j\\). \\(c_j = \\sum_{i=1}^n w_{ij}\\) is the total numer of games lost by team \\(j\\). The term inside the sum works according to the above described mechanism: Wins against an opponent \\(j\\) with high strength (i.e. high \\(p_j\\)) get more weight, while wins against an opponent with a high number of total games lost (i.e. high \\(c_j\\)) get less weight. This is then summed up across all opponents and weighted by the damping factor \\(d \\in [0,1)\\) (usually, \\(d\\) is set to 0.85). \\(d\\) guarantees the existence of (finite) soultions even if there is a team that always won or always lost.\nThe above can be written in matrix-vector notation as follows: \\[ \\textbf{p} = (1-d) \\, \\textbf{e} + d \\, \\textbf{W} \\,\\textbf{D}_c^{-1} \\, \\textbf{p} \\] where \\(\\textbf{p}=[p_1, \\dots, p_n]^T\\) is the PageRank strength vector and \\(\\textbf{e}\\) is an \\(n\\)-dimensional vector of ones. \\(\\textbf{D}=\\text{diag}(c_1, \\dots, c_n)\\) is a diagonal matrix and \\(\\textbf{W}\\) is the win matrix introduced above.\nTo get a unique solution, PageRank requires a restriction on the scale of the strength vector. Therefore, the restriction that \\(\\textbf{p}\\) must to sum up to \\(n\\), i.e. \\(\\textbf{e}^T \\, \\textbf{p} = n\\), is introduced. This is the same as saying that the average strength is 1. Using this, the following holds: \\[ \\textbf{e} = \\frac{\\textbf{e} \\, \\textbf{e}^T \\, \\textbf{p}}{n}\\] Plugging this into the recursive formula for \\(\\textbf{p}\\) and factoring out \\(\\textbf{p}\\) on the right hand side yields: \\[ \\begin{align}\n\\textbf{p} &= \\left[ (1-d) \\, \\textbf{e} \\, \\textbf{e}^T/n + d \\, \\textbf{W} \\,\\textbf{D}_c^{-1} \\right] \\textbf{p} \\\\\n&= \\mathbf{A} \\, \\mathbf{p}\n\\end{align}\\]\nSo the PageRank strength vector is the eigenvector corresponding to an eigenvalue of 1 of matrix \\(\\textbf{A}\\). In fact, it can be shown that 1 is the largest eigenvalue of \\(\\textbf{A}\\). It is known that the power iteration (or Von Mises iteration) method converges to the eigenvector corresponding to the largest eigenvalue, in this case the eigenvector corresponding to the eigenvalue 1. So given some initial vector\\(\\textbf{p}_0\\), the PageRank strength vector can be calculated iteratively as: \\[\n\\begin{align}\n\\textbf{p}^{(t+1)} &\\gets \\textbf{A} \\, \\textbf{p}^{(t)} \\\\\n\\textbf{p}^{(t+1)} &\\gets \\frac{\\textbf{p}^{(t+1)}}{\\textbf{e}^T \\, \\textbf{p}^{(t+1)}} n\n\\end{align}\n\\] The second operation is a normalization ensuring that \\(\\textbf{e}^T \\, \\textbf{p}^{(t+1)} = n\\) Hastie et al. (2009)."
  },
  {
    "objectID": "blog/MLforAssetManagement/MLforAssetManagement.html#implementation-1",
    "href": "blog/MLforAssetManagement/MLforAssetManagement.html#implementation-1",
    "title": "Machine Learning for Managing Stock Portfolios",
    "section": "Implementation",
    "text": "Implementation\nBelow, you can see my implementation of the PageRank approach.\n\nmy_pagerank &lt;- function(W, d=0.85, n_iter=1000){\n  n &lt;- dim(W)[1]\n  c &lt;- colSums(W)\n  A &lt;- (1-d)*rep(1,n) %*% t(rep(1,n))/n + d*W%*%diag(1/c)\n  \n  # initialize pagerank strength vector\n  # with all teams equally strong\n  p &lt;- rep(1/n, n)\n  names(p) &lt;- colnames(W)\n  \n  # power iteration\n  for (t in 1:n_iter) {\n    p &lt;- A%*%p\n    p &lt;- (p/sum(p))*n\n  }\n  \n  return(p)\n}\n\nLet’s apply my implementation of the PageRank to the win matrix.\n\nmy_pagerank_est &lt;- my_pagerank(W)\nhead(my_pagerank_est)\n\n                       [,1]\nArizona Cardinals 0.7385196\nAtlanta Falcons   1.2251638\nBaltimore Ravens  1.9602687\nBuffalo Bills     2.2841688\nCarolina Panthers 0.4254393\nChicago Bears     0.5206048\n\n\nAnd again I visualize the estimated strengths and the ranking using a horizontal bar char.\n\n\nShow code\ndf &lt;- data.frame(\n  team = rownames(my_pagerank_est),\n  score = as.numeric(my_pagerank_est)\n)\n\nggplot(df, aes(reorder(team, score), y=score)) +\n  geom_col(fill=\"#d72638\") +\n  coord_flip() +\n  labs(title=\"Ranking and Strength based on PageRank\",\n       y=\"Strength\",\n       x=\"Team\") +\n  theme_light()\n\n\n\n\n\n\n\n\n\nAs for the Bradley-Terry model, I want to compare my from-scratch implementation of PageRank to the one provided by the igraph R package. Before actually compute the PageRank strength, the igraph package requires to construct a graph using the transpose of the win matrix as adjacency matrix.\n\n# construct graph from tranpose of win matrix\ngraphObj &lt;- igraph::graph_from_adjacency_matrix(t(W), weighted = TRUE, mode = \"directed\")\n\n# run pagerank\npackage_pagerank_est &lt;- igraph::page_rank(graphObj)$vector\n\n# compare results\npagerank_compare &lt;- cbind(\"my_pagerank_est\"=my_pagerank_est, package_pagerank_est, \"ratio\"=my_pagerank_est/package_pagerank_est)\nhead(pagerank_compare)\n\n                            package_pagerank_est   \nArizona Cardinals 0.7385196           0.02307874 32\nAtlanta Falcons   1.2251638           0.03828637 32\nBaltimore Ravens  1.9602687           0.06125840 32\nBuffalo Bills     2.2841688           0.07138027 32\nCarolina Panthers 0.4254393           0.01329498 32\nChicago Bears     0.5206048           0.01626890 32\n\n\nObviously, my values and the values returned by the igraph package are not the same. However, when dividing them by each other it becomes apparent that my values are just 32 times the values returned by the package. The reason for the difference in scale is the following: The igraph package uses as restriction on the strength vector that it sums up to 1. However, I use as restriction that the strength vector sums up to \\(n=32\\). Importantly, this difference in scaling has no influence on the rankings."
  },
  {
    "objectID": "blog/OfflineRLforDynamicPricing/OfflineRLforDynamicPricing.html",
    "href": "blog/OfflineRLforDynamicPricing/OfflineRLforDynamicPricing.html",
    "title": "Offline Reinforcement Learning for Dynamic Pricing",
    "section": "",
    "text": "here goes the text"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "My name is Dominik and I am a statistician. I love working with data, solving complex problems, and turning insights into impact.\nMy journey has taken me from studying maths and business at TUM to diving deep into statistics and machine learning. Currently, I am a Ph.D. candidate at the Chair of Statistics at the University of the Bundeswehr Munich. I have already had the opportunity to gather some practical experience through internships (e.g. at Allianz) and project work (PwC in cooperation with TUM Data Innovation Lab).\nFor me, work is most fun when you develop together data-driven solutions and put them into practice. I love expanding my skills continuously, e.g., by taking online courses or reading scientific literature on topics that are new to me.\nIn my leisure time, I enjoy rowing in a crew, cooking, travelling and reading."
  }
]